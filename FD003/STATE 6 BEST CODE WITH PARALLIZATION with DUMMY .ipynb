{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([[0.9900, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9900, 0.0100, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9900, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1.7067, 1.8330, 4.4101, 0.4517, 1.9803, 0.9126, 2.1999, 1.6665, 1.0528,\n",
       "         3.8107, 4.1096, 2.5276, 3.1345, 3.8671, 5.1453, 2.8676, 4.3587, 3.3928,\n",
       "         3.5012, 3.6997, 5.0395, 4.0577, 3.4248, 2.0775, 3.0044, 3.5906, 3.3729,\n",
       "         1.6450, 3.0148, 2.9634, 3.2845, 3.8130, 1.7699, 4.3630, 3.7296, 4.2514,\n",
       "         8.4255, 8.3495, 9.5776, 6.4066, 6.0608, 8.4153, 3.8664, 2.2424, 2.1272,\n",
       "         4.2723, 2.5092, 5.7744, 2.8853, 2.7140, 3.3400, 4.7481, 4.3187, 4.9789,\n",
       "         3.9627, 3.5811, 3.0842, 3.7736, 3.0026, 2.9455, 7.7113, 6.5516, 7.7482,\n",
       "         5.3371, 7.4793, 6.2766, 8.1535]),\n",
       " tensor([ 2.5561,  1.3584,  0.9140,  5.1038,  6.0758,  5.1163,  5.6583,  3.7436,\n",
       "          6.5287,  6.6638,  5.9436,  5.5250,  3.5467,  7.3199,  6.6237,  4.2694,\n",
       "          6.3169,  5.6880,  2.4627,  6.7533,  5.0604,  5.9027,  5.1858,  7.5004,\n",
       "          5.8506,  6.1974,  5.4239,  4.9548,  5.7841,  6.7327,  6.7823,  5.8133,\n",
       "          6.0714,  5.7770,  4.8747,  6.2695,  2.0126,  1.2807,  1.7046,  1.4024,\n",
       "          0.1619, -0.1916,  6.4555,  4.8125,  8.2772,  8.2086,  7.6806,  7.5206,\n",
       "          6.9531,  8.8953,  7.0534,  8.5660,  7.8799,  7.9196,  7.2874,  8.1893,\n",
       "          7.9709,  6.2934,  6.0831,  8.6906,  2.8407,  4.3903,  1.0723,  4.5169,\n",
       "          6.2909,  4.1077,  8.2264]),\n",
       " 67)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the joint state space for two units (4 states each)\n",
    "joint_states = [(i, j) for i in range(4) for j in range(4)]\n",
    "num_joint_states = len(joint_states)\n",
    "# Sort the joint states based on the sum of values in each tuple\n",
    "joint_states = sorted(joint_states, key=lambda x: sum(x))\n",
    "# Example: Define a 4x4 joint transition matrix P((s1, s2) -> (s1', s2'))\n",
    "P_joint = np.array([\n",
    "    # Each row corresponds to a joint state, each column to the next joint state\n",
    "    [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],  # (0,0) -> various states\n",
    "    [0.3, 0.3, 0.1, 0.1, 0.07, 0.05, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (0,1)\n",
    "    [0.2, 0.2, 0.3, 0.1, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,2)\n",
    "    [0.1, 0.1, 0.2, 0.4, 0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,3)\n",
    "    [0.3, 0.2, 0.1, 0.1, 0.2, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (1,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.3, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0],  # (1,1)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.4, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01, 0.0, 0.0],  # (1,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.2, 0.1, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0],  # (1,3)\n",
    "    [0.3, 0.1, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01],  # (2,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.1, 0.4, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01],  # (2,1)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.05, 0.05, 0.3, 0.05, 0.02, 0.02, 0.01, 0.01],  # (2,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.1, 0.3, 0.05, 0.05, 0.02, 0.02],  # (2,3)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.3, 0.1, 0.05, 0.05],  # (3,0)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.3, 0.05, 0.1],  # (3,1)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05, 0.1, 0.4, 0.2],  # (3,2)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # (3,3)\n",
    "])\n",
    "\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i):\n",
    "        P_joint[i, j] = 0\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i+5,16):\n",
    "        P_joint[i, j] = 0\n",
    "\n",
    "P_joint=P_joint+np.eye(16,16)*0.8\n",
    "# Normalize each row so the sum of probabilities equals 1\n",
    "P_joint = P_joint / P_joint.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Check if the rows sum to 1\n",
    "row_sums = P_joint.sum(axis=1)\n",
    "print(row_sums)  # Should all be close to 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P_joint\n",
    "\n",
    "\n",
    "\n",
    "T_matrix=torch.tensor([[0.99, 0.01, 0.0,0.0],\n",
    "        [0.00, 0.99, 0.01,0],\n",
    "        [0.0, 0.00, 0.99,.01],\n",
    "                      [0.0,0.0,0.0,1]], device=device) \n",
    "\n",
    "T_matrix1=torch.zeros(4,4,4)\n",
    "T_matrix1[0,:,:]=T_matrix+torch.eye(4,4)*-0.0\n",
    "T_matrix1[1,:,:]=T_matrix+torch.eye(4,4)*-0.3\n",
    "T_matrix1[2,:,:]=T_matrix+torch.eye(4,4)*-0.5\n",
    "T_matrix1[3,:,:]=T_matrix+torch.eye(4,4)*-0.7\n",
    "\n",
    "T_matrix1=T_matrix1/torch.sum(T_matrix1, 2).reshape(4,4,1)\n",
    "\n",
    "T_matrix1\n",
    "\n",
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "\n",
    "O_matrix_mean=torch.tensor([1.5,3.5,5.5,7.5]).to(device)\n",
    "O_matrix_std=torch.tensor([1.0,1.0,1.0,1.0]).to(device)\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)\n",
    "\n",
    "\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "def simulate_HMM(T_matrix_1,O_matrix,x,t):\n",
    "    x=(0,0)\n",
    "    current_state_idx = joint_states.index(x)\n",
    "    states=[]\n",
    "    t=0\n",
    "    o=[]\n",
    "    o1=[]\n",
    "#     o_1=torch.matmul(x.to(device),O_matrix.to(device))\n",
    "# #         print(o_1)\n",
    "    o.append(Normal(O_matrix_mean[x[0]],1).sample().to(device))\n",
    "    o1.append(Normal(O_matrix_mean[x[1]],1).sample().to(device))\n",
    "    t=1\n",
    "    h=torch.tensor([1,0,0,0.0])\n",
    "    states.append(x)\n",
    "    for i in range(1,5000):\n",
    "#         print(i)\n",
    "        # print(states)\n",
    "        t+=1\n",
    "        p = P_joint[current_state_idx]\n",
    "        # print(current_state_idx)\n",
    "        # Choose the next joint state based on the current transition probabilities\n",
    "        next_state_idx = np.random.choice(range(num_joint_states), p=p)\n",
    "        next_state = joint_states[next_state_idx]\n",
    "        x=next_state\n",
    "        # x[0]=x1.item()\n",
    "        # x[1]=x2.item()\n",
    "        states.append(x)\n",
    "        # print(x[0])\n",
    "        # print(alpha)\n",
    "        o_1,o_2 = MultivariateNormal(torch.stack([O_matrix_mean[x[0]], O_matrix_mean[x[1]]]), \n",
    "                                     torch.tensor([[1, 0.0],\n",
    "                              [0.0, 1]])).sample().t().to(device)\n",
    "        o.append(o_1)\n",
    "        o1.append(o_2)\n",
    "        current_state_idx=next_state_idx\n",
    "\n",
    "        \n",
    "        t1=t\n",
    "        \n",
    "        if x[0]==3 and x[1]==3:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    o=torch.tensor(o).to(device)\n",
    "    o1=torch.tensor(o1).to(device)\n",
    "    return o,o1,t\n",
    "\n",
    "o=simulate_HMM(T_matrix,O_matrix_mean,torch.tensor([1.0,0,0.0]),1000)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27272cb3080>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "# plt.plot(o[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27272c03860>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "plt.plot(o[1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred1=[]\n",
    "# for i in range(0, 100):\n",
    "#             pred1.append(simulate_HMM(T_matrix, O_matrix_mean, s_0, 1))\n",
    "\n",
    "# torch.save(pred1, 'DATA_NON_LINEAR.pth')\n",
    "\n",
    "# print(\"pred1 list saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MAIN MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ATTENTION(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=num_states\n",
    "        self.num_states=num_states\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K, V, t1):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.tanh(self.fc_1(attn_output))+(t1))   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=300):\n",
    "        super().__init__()\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "        \n",
    "        # self.P[:, :, 0::2] = torch.cos(X)\n",
    "        # self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "\n",
    "\n",
    "class ATTENTION1(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION1, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=num_states\n",
    "        self.num_states=num_states\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K,V):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.leaky_relu(self.fc_1(attn_output))+ V )   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(Net, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=4\n",
    "        num_hiddens=4\n",
    "        self.num_states=4\n",
    "        self.s_0 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.s_01 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu1 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.sigma =nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "        self.sigma1 = nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        max_len=300\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc1 = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc2 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc3 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "        self.A1=ATTENTION()\n",
    "        self.A2=ATTENTION()\n",
    "        self.A3=ATTENTION()\n",
    "        self.A4=ATTENTION()\n",
    "        self.A5=ATTENTION()\n",
    "        self.A6=ATTENTION()\n",
    "        self.A7=ATTENTION()\n",
    "        self.A8=ATTENTION()\n",
    "        self.A9=ATTENTION()\n",
    "        self.A10=ATTENTION()\n",
    "\n",
    "        # LSTM Encoder\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm3 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm4 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        \n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(hidden_dim, 0)\n",
    "    def forward(self,  t, pred,pred1, prob=0.3):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def training1(self,  t, pred,pred1,m1,m2, prob=0.0):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        #pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        #pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            #print(o_1.shape)\n",
    "            #print(new_pred[:,:,i].shape)\n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states)).cuda()\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states)).cuda()\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1*m1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1*m2, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def state_filter(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "       \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred_1, pred1_1\n",
    "        \n",
    "    def state_filter1(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "        #     pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "        #     pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        # pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        # pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred, pred1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with a padding value.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = torch.full((len(sequences), max_length), padding_value, dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "    \n",
    "    return padded_sequences, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with the last value of each sequence.\n",
    "    Returns the padded sequences and a mask indicating the original positions.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = torch.zeros((len(sequences), max_length), dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "        \n",
    "        # Fill the remaining positions with the last value of the sequence\n",
    "        if length > 0:  # Check to ensure sequence is not empty\n",
    "            padded_sequences[i, length:] = seq[-1]\n",
    "    \n",
    "    return padded_sequences, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with the last value of each sequence.\n",
    "    Returns the padded sequences and a mask indicating the original positions.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    print(max_length)\n",
    "    padded_sequences = torch.zeros((len(sequences), max_length), dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    # Collect the last values from all sequences\n",
    "    last_values = [seq[-1] for seq in sequences if len(seq) > 0]\n",
    "    last_values_tensor = torch.tensor(last_values, dtype=torch.float32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "        \n",
    "        if length > 0:  # Ensure the sequence is not empty\n",
    "            random_indices = torch.randint(0, len(last_values_tensor), (max_length - length,))\n",
    "            random_values = last_values_tensor[random_indices]\n",
    "            padded_sequences[i, length:] = random_values\n",
    "    \n",
    "    return padded_sequences, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n",
    "\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=(e2-e1)**2\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7792\\3374062728.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pred1 = torch.load('TRAIN_DATA_NON_LINEAR.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7792\\502618589.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7792\\4031529318.py:222: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7792\\4031529318.py:223: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-407.03265380859375\n",
      "tensor([-3.1257, -2.2153, -0.2851, -0.2817], device='cuda:0')\n",
      "tensor([1.3451, 1.9904, 2.5915, 3.6508], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 2/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-411.72296142578125\n",
      "tensor([-41.5250,  -5.9280,   0.5796,  -3.5954], device='cuda:0')\n",
      "tensor([1.3567, 2.0152, 2.6175, 3.6692], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 3/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.6156921386719\n",
      "tensor([17.5978,  6.0930, -0.3600,  0.1997], device='cuda:0')\n",
      "tensor([1.5088, 2.3636, 3.5428, 6.7049], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 4/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-428.3894958496094\n",
      "tensor([ 4.5890, -6.1076, -7.4978, -0.0823], device='cuda:0')\n",
      "tensor([1.5071, 2.3660, 3.5410, 6.6902], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 5/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.7408447265625\n",
      "tensor([-6.4030, -0.8612, -0.5937, -0.0071], device='cuda:0')\n",
      "tensor([1.5022, 2.3574, 3.5372, 6.6890], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 6/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-409.03741455078125\n",
      "tensor([20.3450, 10.6577,  6.8058,  2.7183], device='cuda:0')\n",
      "tensor([1.3368, 1.9748, 2.5762, 3.6444], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 7/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-430.105224609375\n",
      "tensor([-33.7074, -18.9894, -15.5795,   0.3832], device='cuda:0')\n",
      "tensor([1.5017, 2.3573, 3.5401, 6.7025], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 8/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.0290832519531\n",
      "tensor([-2.1324,  0.8125, -3.0216,  0.3863], device='cuda:0')\n",
      "tensor([1.5085, 2.3629, 3.5424, 6.7026], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 9/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.5669250488281\n",
      "tensor([-11.4801, -11.9547,  -4.2948,  -0.1649], device='cuda:0')\n",
      "tensor([1.4997, 2.3580, 3.5432, 6.7006], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 10/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-433.83544921875\n",
      "tensor([-1.1389, -0.3354, -0.0291, -0.0493], device='cuda:0')\n",
      "tensor([1.5007, 2.3599, 3.5457, 6.7129], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "pred1 = torch.load('TRAIN_DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Parameters for experiment\n",
    "batch_size = 100\n",
    "num_epochs = 10000\n",
    "n_trials = 10\n",
    "learning_rate = 0.01\n",
    "device='cuda'\n",
    "# Initialize result containers\n",
    "all_losses = []\n",
    "all_l1 = []\n",
    "all_l2 = []\n",
    "trial_times = []\n",
    "final_mu_values = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial {trial + 1}/{n_trials}\")\n",
    "    trial_start_time = time.time()\n",
    "\n",
    "    net = Net().to(device)  # Initialize model\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=num_epochs)\n",
    "\n",
    "    net.train()\n",
    "    trial_losses = []\n",
    "    trial_l1 = []\n",
    "    trial_l2 = []\n",
    "    # Extract observations and underlying states\n",
    "    observations_o = [o for o, _, _ in pred1]\n",
    "    observations_o1 = [o for _, o, _ in pred1]\n",
    "   \n",
    "    observations_o, m1 = pad_sequences(observations_o, padding_value=-1)\n",
    "    observations_o1, m2 = pad_sequences(observations_o1, padding_value=-1)\n",
    "    observations_o=observations_o.cuda()\n",
    "    observations_o1=observations_o1.cuda()\n",
    "    m1=m1.cuda()\n",
    "    m2=m2.cuda()\n",
    "    m_1=m1.clone()\n",
    "    m_2=m2.clone()\n",
    "    print(m1.sum())\n",
    "    m_1[:,:-100]=1\n",
    "    m_2[:,:-100]=1\n",
    "    print(m_1.sum())\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.t = 0  # Reset any time-dependent states\n",
    "\n",
    "        # Create random batch indices\n",
    "    \n",
    "\n",
    "        loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        l1,l2,_=net.training1(0, observations_o, observations_o1,m_1,m_2, 0.0)\n",
    "        loss -= (torch.mean(l1) + torch.mean(l2))\n",
    "\n",
    "        # Add L1 regularization\n",
    "        # l1_reg = torch.tensor(0., device=device)\n",
    "        # for param in net.parameters():\n",
    "        #     l1_reg += torch.norm(param, 1)\n",
    "\n",
    "        # # Update loss\n",
    "        # loss += 0.01 * l1_reg\n",
    "        #print(loss)\n",
    "        trial_losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    l1,l2,_=net.training1(0, observations_o, observations_o1,m1,m2, 0.0)\n",
    "    loss = (torch.mean(l1) + torch.mean(l2))\n",
    "    # Save trial results\n",
    "    print((loss.item()))\n",
    "    print(net.mu.grad)\n",
    "    print(torch.cumsum(torch.exp(net.mu),dim=0))\n",
    "    all_losses.append(loss.item())\n",
    "    trial_times.append(time.time() - trial_start_time)\n",
    "    final_mu_values.append(torch.cumsum(torch.exp(net.mu),dim=0).detach().cpu().numpy())\n",
    "\n",
    "    # Save filtered states\n",
    "    net.cpu()\n",
    "    observations_o=observations_o.cpu()\n",
    "    observations_o1=observations_o1.cpu()\n",
    "   \n",
    "\n",
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)\n",
    "\n",
    "# # Plot loss curve\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for trial_losses in all_losses:\n",
    "#     plt.plot(trial_losses, alpha=0.7)\n",
    "# plt.title('Loss Curve Across Trials')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.3450664, 1.9904281, 2.5914578, 3.6507893], dtype=float32),\n",
       " array([1.3567458, 2.015243 , 2.617528 , 3.6691732], dtype=float32),\n",
       " array([1.5088458, 2.363577 , 3.5428283, 6.704913 ], dtype=float32),\n",
       " array([1.50711  , 2.3659992, 3.540969 , 6.690222 ], dtype=float32),\n",
       " array([1.5021507, 2.3573513, 3.5372367, 6.68897  ], dtype=float32),\n",
       " array([1.3367866, 1.9748299, 2.5761528, 3.6443875], dtype=float32),\n",
       " array([1.5016897, 2.3573499, 3.54005  , 6.702525 ], dtype=float32),\n",
       " array([1.5085154, 2.3629262, 3.5424142, 6.7025805], dtype=float32),\n",
       " array([1.4996661, 2.3579798, 3.5431647, 6.7005634], dtype=float32),\n",
       " array([1.5007352, 2.359919 , 3.5456686, 6.712945 ], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mu_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred1 = torch.load('DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Parameters for experiment\n",
    "batch_size = 100\n",
    "num_epochs = 10000\n",
    "n_trials = 10\n",
    "learning_rate = 0.01\n",
    "device='cuda'\n",
    "# Initialize result containers\n",
    "all_losses = []\n",
    "all_l1 = []\n",
    "all_l2 = []\n",
    "trial_times = []\n",
    "final_mu_values = []\n",
    "# Parameters for early stopping\n",
    "patience = 200000  # Number of epochs to wait for improvement\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial {trial + 1}/{n_trials}\")\n",
    "    trial_start_time = time.time()\n",
    "\n",
    "    net = Net().to(device)  # Initialize model\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.0001, total_iters=num_epochs)\n",
    "\n",
    "    net.train()\n",
    "    trial_losses = []\n",
    "    trial_l1 = []\n",
    "    trial_l2 = []\n",
    "    # Extract observations and underlying states\n",
    "    observations_o = [o for o, _, _, _ in pred1]\n",
    "    observations_o1 = [o for _, o, _, _ in pred1]\n",
    "    true_states = [t.numpy()[:, 0:1] for _, _, _, t in pred1]\n",
    "    true_states1 = [t.numpy()[:, 1:2] for _, _, _, t in pred1]\n",
    "    observations_o, m1 = pad_sequences(observations_o, padding_value=-1)\n",
    "    observations_o1, m2 = pad_sequences(observations_o1, padding_value=-1)\n",
    "    observations_o = observations_o.cuda()\n",
    "    observations_o1 = observations_o1.cuda()\n",
    "    m1 = m1.cuda()\n",
    "    m2 = m2.cuda()\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        net.t = 0  # Reset any time-dependent states\n",
    "\n",
    "        # Create random batch indices\n",
    "        loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        l1, l2, _ = net.training1(0, observations_o, observations_o1, m1, m2, 0.0)\n",
    "        loss -= (torch.mean(l1) + torch.mean(l2))\n",
    "\n",
    "        trial_losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Check early stopping\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model_state = net.state_dict()  # Save the best model state\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Save trial results\n",
    "    print(f\"Final Loss for Trial {trial + 1}: {loss.item()}\")\n",
    "    all_losses.append(best_loss)\n",
    "    trial_times.append(time.time() - trial_start_time)\n",
    "    final_mu_values.append(net.mu.detach().cpu().numpy())\n",
    "\n",
    "    # Load the best model state for evaluation\n",
    "    net.load_state_dict(best_model_state)\n",
    "\n",
    "    # Save filtered states\n",
    "    net.cpu()\n",
    "    observations_o = observations_o.cpu()\n",
    "    observations_o1 = observations_o1.cpu()\n",
    "    m1 = m1.cpu()\n",
    "    m2 = m2.cpu()\n",
    "    for i in range(0, batch_size):\n",
    "        o, o1, t, states = pred1[i]\n",
    "        o, o1 = o.to('cpu'), o1.to('cpu')\n",
    "        filtered_l1, filtered_l2 = net.state_filter(t, o, o1, 0.0)\n",
    "        trial_l1.append(torch.argmax(filtered_l1, dim=2)[0])\n",
    "        trial_l2.append(torch.argmax(filtered_l2, dim=2)[0])\n",
    "\n",
    "    all_l1.append(trial_l1)\n",
    "    all_l2.append(trial_l2)\n",
    "\n",
    "# Compute statistics across trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc): Linear(in_features=5, out_features=4, bias=False)\n",
       "  (fc1): Linear(in_features=5, out_features=4, bias=False)\n",
       "  (fc2): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (fc3): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (fc4): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (fc5): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (A1): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A2): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A3): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A4): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A5): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A6): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A7): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A8): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A9): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A10): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (lstm1): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm2): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm3): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm4): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trial_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591.909423828125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(trial_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-407.03265380859375,\n",
       " -411.72296142578125,\n",
       " -431.6156921386719,\n",
       " -428.3894958496094,\n",
       " -431.7408447265625,\n",
       " -409.03741455078125,\n",
       " -430.105224609375,\n",
       " -431.0290832519531,\n",
       " -431.5669250488281,\n",
       " -433.83544921875]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "Mean Loss (Final Epoch): 424.6075744628906, Std Loss: 10.18168611550171\n",
      "Mean Training Time: 2534.158217024803s, Std Training Time: 111.74268628379552s\n",
      "Final mu values (across trials): [[1.3450664 1.9904281 2.5914578 3.6507893]\n",
      " [1.3567458 2.015243  2.617528  3.6691732]\n",
      " [1.5088458 2.363577  3.5428283 6.704913 ]\n",
      " [1.50711   2.3659992 3.540969  6.690222 ]\n",
      " [1.5021507 2.3573513 3.5372367 6.68897  ]\n",
      " [1.3367866 1.9748299 2.5761528 3.6443875]\n",
      " [1.5016897 2.3573499 3.54005   6.702525 ]\n",
      " [1.5085154 2.3629262 3.5424142 6.7025805]\n",
      " [1.4996661 2.3579798 3.5431647 6.7005634]\n",
      " [1.5007352 2.359919  3.5456686 6.712945 ]]\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(\"Training Results:\")\n",
    "print(f\"Mean Loss (Final Epoch): {-mean_losses}, Std Loss: {std_losses}\")\n",
    "print(f\"Mean Training Time: {mean_trial_time}s, Std Training Time: {std_trial_time}s\")\n",
    "print(f\"Final mu values (across trials): {np.array(final_mu_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred1[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pred1[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State filtering MSE\n",
    "true_states = [t.numpy()[:, 0:1] for _, _, _, t in pred1]\n",
    "true_states1 = [t.numpy()[:, 1:2] for _, _, _, t in pred1]\n",
    "\n",
    "trial_mse_l1 = []\n",
    "trial_mse_l2 = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    mse_l1 = 0.0\n",
    "    mse_l2 = 0.0\n",
    "    total_states = 0\n",
    "\n",
    "    l1 = all_l1[trial]\n",
    "    l2 = all_l2[trial]\n",
    "\n",
    "    for filtered_l1, filtered_l2, ts, ts1 in zip(l1, l2, true_states, true_states1):\n",
    "        mse_l1 += (np.diag(filtered_l1.detach().numpy() == ts) ).sum()\n",
    "        # print(filtered_l1.shape)\n",
    "        # print(ts.shape)\n",
    "        mse_l2 += (np.diag(filtered_l2.detach().numpy() ==  ts1)).sum()\n",
    "        total_states += ts.shape[0]\n",
    "    # print(mse_l1)\n",
    "    # print(total_states)\n",
    "    \n",
    "\n",
    "    mse_l1 /= total_states\n",
    "    mse_l2 /= total_states\n",
    "\n",
    "    trial_mse_l1.append(mse_l1)\n",
    "    trial_mse_l2.append(mse_l2)\n",
    "\n",
    "# Calculate average error and standard deviation\n",
    "average_mse_l1 = np.mean(trial_mse_l1)\n",
    "std_mse_l1 = np.std(trial_mse_l1)\n",
    "\n",
    "average_mse_l2 = np.mean(trial_mse_l2)\n",
    "std_mse_l2 = np.std(trial_mse_l2)\n",
    "\n",
    "# Print results\n",
    "print(\"State Filtering MSE Results:\")\n",
    "print(f\"Average MSE for l1: {average_mse_l1:.4f}, Std Dev: {std_mse_l1:.4f}\")\n",
    "print(f\"Average MSE for l2: {average_mse_l2:.4f}, Std Dev: {std_mse_l2:.4f}\")\n",
    "\n",
    "# Print MSE for each trial\n",
    "for trial, (mse_l1, mse_l2) in enumerate(zip(trial_mse_l1, trial_mse_l2), 1):\n",
    "    print(f\"Trial {trial}: MSE l1 = {mse_l1:.4f}, MSE l2 = {mse_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mse_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_mse_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of parameters\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
