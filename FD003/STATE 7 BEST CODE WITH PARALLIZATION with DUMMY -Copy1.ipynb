{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([[0.9900, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9900, 0.0100, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9900, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0098, 0.3310, 2.0824, 1.8462, 0.5999, 1.8945, 1.9157, 1.4958, 2.2820,\n",
       "         0.5463, 1.3155, 2.0615, 2.8473, 4.6283, 4.6958, 6.3030, 5.2595, 4.4528,\n",
       "         6.0292, 3.8083, 6.2304, 5.3763, 5.2081, 6.8628, 5.1963, 6.4926, 5.0440,\n",
       "         1.6568, 2.9193, 2.5196, 4.0030, 3.3602, 3.2348, 3.4541, 3.6737, 2.9427,\n",
       "         3.6210, 7.3800, 5.7371]),\n",
       " tensor([ 0.6034,  1.1923,  3.6788, -0.1283,  1.0422,  1.9004,  2.0876,  3.6645,\n",
       "          3.4100,  3.2628,  4.2427,  2.0146,  2.7150,  2.5034,  2.0291,  1.5767,\n",
       "          0.4099, -0.4849,  1.6358,  1.1623,  2.6987,  2.9889,  3.3253,  3.0539,\n",
       "          1.6239,  2.0926,  4.3871,  4.9164,  5.4680,  6.1672,  6.4997,  8.2842,\n",
       "          8.4095,  6.5281,  8.7911,  6.0651,  8.4723,  6.7358,  6.9325]),\n",
       " 39)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the joint state space for two units (4 states each)\n",
    "joint_states = [(i, j) for i in range(4) for j in range(4)]\n",
    "num_joint_states = len(joint_states)\n",
    "# Sort the joint states based on the sum of values in each tuple\n",
    "joint_states = sorted(joint_states, key=lambda x: sum(x))\n",
    "# Example: Define a 4x4 joint transition matrix P((s1, s2) -> (s1', s2'))\n",
    "P_joint = np.array([\n",
    "    # Each row corresponds to a joint state, each column to the next joint state\n",
    "    [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],  # (0,0) -> various states\n",
    "    [0.3, 0.3, 0.1, 0.1, 0.07, 0.05, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (0,1)\n",
    "    [0.2, 0.2, 0.3, 0.1, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,2)\n",
    "    [0.1, 0.1, 0.2, 0.4, 0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,3)\n",
    "    [0.3, 0.2, 0.1, 0.1, 0.2, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (1,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.3, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0],  # (1,1)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.4, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01, 0.0, 0.0],  # (1,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.2, 0.1, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0],  # (1,3)\n",
    "    [0.3, 0.1, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01],  # (2,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.1, 0.4, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01],  # (2,1)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.05, 0.05, 0.3, 0.05, 0.02, 0.02, 0.01, 0.01],  # (2,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.1, 0.3, 0.05, 0.05, 0.02, 0.02],  # (2,3)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.3, 0.1, 0.05, 0.05],  # (3,0)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.3, 0.05, 0.1],  # (3,1)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05, 0.1, 0.4, 0.2],  # (3,2)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # (3,3)\n",
    "])\n",
    "\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i):\n",
    "        P_joint[i, j] = 0\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i+5,16):\n",
    "        P_joint[i, j] = 0\n",
    "\n",
    "P_joint=P_joint+np.eye(16,16)*0.8\n",
    "# Normalize each row so the sum of probabilities equals 1\n",
    "P_joint = P_joint / P_joint.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Check if the rows sum to 1\n",
    "row_sums = P_joint.sum(axis=1)\n",
    "print(row_sums)  # Should all be close to 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P_joint\n",
    "\n",
    "\n",
    "\n",
    "T_matrix=torch.tensor([[0.99, 0.01, 0.0,0.0],\n",
    "        [0.00, 0.99, 0.01,0],\n",
    "        [0.0, 0.00, 0.99,.01],\n",
    "                      [0.0,0.0,0.0,1]], device=device) \n",
    "\n",
    "T_matrix1=torch.zeros(4,4,4)\n",
    "T_matrix1[0,:,:]=T_matrix+torch.eye(4,4)*-0.0\n",
    "T_matrix1[1,:,:]=T_matrix+torch.eye(4,4)*-0.3\n",
    "T_matrix1[2,:,:]=T_matrix+torch.eye(4,4)*-0.5\n",
    "T_matrix1[3,:,:]=T_matrix+torch.eye(4,4)*-0.7\n",
    "\n",
    "T_matrix1=T_matrix1/torch.sum(T_matrix1, 2).reshape(4,4,1)\n",
    "\n",
    "T_matrix1\n",
    "\n",
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "\n",
    "O_matrix_mean=torch.tensor([1.5,3.5,5.5,7.5]).to(device)\n",
    "O_matrix_std=torch.tensor([1.0,1.0,1.0,1.0]).to(device)\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)\n",
    "\n",
    "\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "def simulate_HMM(T_matrix_1,O_matrix,x,t):\n",
    "    x=(0,0)\n",
    "    current_state_idx = joint_states.index(x)\n",
    "    states=[]\n",
    "    t=0\n",
    "    o=[]\n",
    "    o1=[]\n",
    "#     o_1=torch.matmul(x.to(device),O_matrix.to(device))\n",
    "# #         print(o_1)\n",
    "    o.append(Normal(O_matrix_mean[x[0]],1).sample().to(device))\n",
    "    o1.append(Normal(O_matrix_mean[x[1]],1).sample().to(device))\n",
    "    t=1\n",
    "    h=torch.tensor([1,0,0,0.0])\n",
    "    states.append(x)\n",
    "    for i in range(1,5000):\n",
    "#         print(i)\n",
    "        # print(states)\n",
    "        t+=1\n",
    "        p = P_joint[current_state_idx]\n",
    "        # print(current_state_idx)\n",
    "        # Choose the next joint state based on the current transition probabilities\n",
    "        next_state_idx = np.random.choice(range(num_joint_states), p=p)\n",
    "        next_state = joint_states[next_state_idx]\n",
    "        x=next_state\n",
    "        # x[0]=x1.item()\n",
    "        # x[1]=x2.item()\n",
    "        states.append(x)\n",
    "        # print(x[0])\n",
    "        # print(alpha)\n",
    "        o_1,o_2 = MultivariateNormal(torch.stack([O_matrix_mean[x[0]], O_matrix_mean[x[1]]]), \n",
    "                                     torch.tensor([[1, 0.0],\n",
    "                              [0.0, 1]])).sample().t().to(device)\n",
    "        o.append(o_1)\n",
    "        o1.append(o_2)\n",
    "        current_state_idx=next_state_idx\n",
    "\n",
    "        \n",
    "        t1=t\n",
    "        \n",
    "        if x[0]==3 and x[1]==3:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    o=torch.tensor(o).to(device)\n",
    "    o1=torch.tensor(o1).to(device)\n",
    "    return o,o1,t\n",
    "\n",
    "o=simulate_HMM(T_matrix,O_matrix_mean,torch.tensor([1.0,0,0.0]),1000)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a295f8cc20>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "# plt.plot(o[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a296019910>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "plt.plot(o[1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred1=[]\n",
    "# for i in range(0, 100):\n",
    "#             pred1.append(simulate_HMM(T_matrix, O_matrix_mean, s_0, 1))\n",
    "\n",
    "# torch.save(pred1, 'DATA_NON_LINEAR.pth')\n",
    "\n",
    "# print(\"pred1 list saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MAIN MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ATTENTION(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=num_states\n",
    "        self.num_states=num_states\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K, V, t1):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.tanh(self.fc_1(attn_output))+(t1))   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=300):\n",
    "        super().__init__()\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "        \n",
    "        # self.P[:, :, 0::2] = torch.cos(X)\n",
    "        # self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "\n",
    "\n",
    "class ATTENTION1(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION1, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=num_states\n",
    "        self.num_states=num_states\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K,V):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.leaky_relu(self.fc_1(attn_output))+ V )   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(Net, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=4\n",
    "        num_hiddens=4\n",
    "        self.num_states=4\n",
    "        self.s_0 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.s_01 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu1 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.sigma =nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "        self.sigma1 = nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        max_len=300\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc1 = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc2 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc3 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "        self.A1=ATTENTION()\n",
    "        self.A2=ATTENTION()\n",
    "        self.A3=ATTENTION()\n",
    "        self.A4=ATTENTION()\n",
    "        self.A5=ATTENTION()\n",
    "        self.A6=ATTENTION()\n",
    "        self.A7=ATTENTION()\n",
    "        self.A8=ATTENTION()\n",
    "        self.A9=ATTENTION()\n",
    "        self.A10=ATTENTION()\n",
    "\n",
    "        # LSTM Encoder\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm3 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm4 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        \n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(hidden_dim, 0)\n",
    "    def forward(self,  t, pred,pred1, prob=0.3):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def training1(self,  t, pred,pred1,m1,m2, prob=0.0):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        #pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        #pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            #print(o_1.shape)\n",
    "            #print(new_pred[:,:,i].shape)\n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states)).cuda()\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states)).cuda()\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1*m1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1*m2, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def state_filter(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "       \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred_1, pred1_1\n",
    "        \n",
    "    def state_filter1(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "        #     pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "        #     pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        # pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        # pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred, pred1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with a padding value.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = torch.full((len(sequences), max_length), padding_value, dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "    \n",
    "    return padded_sequences, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with the last value of each sequence.\n",
    "    Returns the padded sequences and a mask indicating the original positions.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = torch.zeros((len(sequences), max_length), dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "        \n",
    "        # Fill the remaining positions with the last value of the sequence\n",
    "        if length > 0:  # Check to ensure sequence is not empty\n",
    "            padded_sequences[i, length:] = seq[-1]\n",
    "    \n",
    "    return padded_sequences, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with the last value of each sequence.\n",
    "    Returns the padded sequences and a mask indicating the original positions.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    print(max_length)\n",
    "    padded_sequences = torch.zeros((len(sequences), max_length), dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    # Collect the last values from all sequences\n",
    "    last_values = [seq[-1] for seq in sequences if len(seq) > 0]\n",
    "    last_values_tensor = torch.tensor(last_values, dtype=torch.float32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "        \n",
    "        if length > 0:  # Ensure the sequence is not empty\n",
    "            random_indices = torch.randint(0, len(last_values_tensor), (max_length - length,))\n",
    "            random_values = last_values_tensor[random_indices]\n",
    "            padded_sequences[i, length:] = random_values\n",
    "    \n",
    "    return padded_sequences, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n",
    "\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=(e2-e1)**2\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14412\\3374062728.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pred1 = torch.load('TRAIN_DATA_NON_LINEAR.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14412\\502618589.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14412\\4031529318.py:222: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14412\\4031529318.py:223: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-408.9480895996094\n",
      "tensor([-10.3896,  -3.6651,  -0.2131,   0.0470], device='cuda:0')\n",
      "tensor([1.3446, 2.0029, 2.6074, 3.6621], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 2/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-432.67340087890625\n",
      "tensor([-2.4008, -1.1405, -0.3696, -0.3747], device='cuda:0')\n",
      "tensor([1.5046, 2.3607, 3.5296, 6.6993], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 3/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.3787841796875\n",
      "tensor([22.2112,  9.5439,  2.3272,  0.4756], device='cuda:0')\n",
      "tensor([1.5067, 2.3625, 3.5337, 6.6953], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 4/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-430.7692565917969\n",
      "tensor([19.0643,  7.2980,  2.0688,  0.2455], device='cuda:0')\n",
      "tensor([1.5034, 2.3607, 3.5380, 6.7040], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 5/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.385009765625\n",
      "tensor([-1.8150e+02, -5.3724e+01, -5.8239e+00, -1.7095e-01], device='cuda:0')\n",
      "tensor([1.5041, 2.3593, 3.5345, 6.7014], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 6/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-429.46380615234375\n",
      "tensor([-28.5079,  -9.0281,  -5.4539,  -0.2615], device='cuda:0')\n",
      "tensor([1.5032, 2.3560, 3.5281, 6.7059], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 7/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-430.73284912109375\n",
      "tensor([-13.2288,  -5.1339,   0.8898,   0.8663], device='cuda:0')\n",
      "tensor([1.5031, 2.3609, 3.5336, 6.6935], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 8/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-429.91241455078125\n",
      "tensor([66.0997, 33.6498,  5.9608,  1.1167], device='cuda:0')\n",
      "tensor([1.5047, 2.3602, 3.5272, 6.7027], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 9/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.4179382324219\n",
      "tensor([43.8690, 27.7090, 11.1129,  1.4011], device='cuda:0')\n",
      "tensor([1.5052, 2.3617, 3.5272, 6.7005], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 10/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.98370361328125\n",
      "tensor([ 9.6365,  3.3585,  2.6004, -0.0254], device='cuda:0')\n",
      "tensor([1.4989, 2.3526, 3.5274, 6.6959], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "pred1 = torch.load('TRAIN_DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Parameters for experiment\n",
    "batch_size = 100\n",
    "num_epochs = 10000\n",
    "n_trials = 10\n",
    "learning_rate = 0.01\n",
    "device='cuda'\n",
    "# Initialize result containers\n",
    "all_losses = []\n",
    "all_l1 = []\n",
    "all_l2 = []\n",
    "trial_times = []\n",
    "final_mu_values = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial {trial + 1}/{n_trials}\")\n",
    "    trial_start_time = time.time()\n",
    "\n",
    "    net = Net().to(device)  # Initialize model\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=num_epochs)\n",
    "\n",
    "    net.train()\n",
    "    trial_losses = []\n",
    "    trial_l1 = []\n",
    "    trial_l2 = []\n",
    "    # Extract observations and underlying states\n",
    "    observations_o = [o for o, _, _ in pred1]\n",
    "    observations_o1 = [o for _, o, _ in pred1]\n",
    "   \n",
    "    observations_o, m1 = pad_sequences(observations_o, padding_value=-1)\n",
    "    observations_o1, m2 = pad_sequences(observations_o1, padding_value=-1)\n",
    "    observations_o=observations_o.cuda()\n",
    "    observations_o1=observations_o1.cuda()\n",
    "    m1=m1.cuda()\n",
    "    m2=m2.cuda()\n",
    "    m_1=m1.clone()\n",
    "    m_2=m2.clone()\n",
    "    print(m1.sum())\n",
    "    m_1[:,:-100]=1\n",
    "    m_2[:,:-100]=1\n",
    "    print(m_1.sum())\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.t = 0  # Reset any time-dependent states\n",
    "\n",
    "        # Create random batch indices\n",
    "    \n",
    "\n",
    "        loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        l1,l2,_=net.training1(0, observations_o, observations_o1,m_1,m_2, 0.0)\n",
    "        loss -= (torch.mean(l1) + torch.mean(l2))\n",
    "\n",
    "        # Add L1 regularization\n",
    "        # l1_reg = torch.tensor(0., device=device)\n",
    "        # for param in net.parameters():\n",
    "        #     l1_reg += torch.norm(param, 1)\n",
    "\n",
    "        # # Update loss\n",
    "        # loss += 0.01 * l1_reg\n",
    "        #print(loss)\n",
    "        trial_losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    l1,l2,_=net.training1(0, observations_o, observations_o1,m1,m2, 0.0)\n",
    "    loss = (torch.mean(l1) + torch.mean(l2))\n",
    "    # Save trial results\n",
    "    print((loss.item()))\n",
    "    print(net.mu.grad)\n",
    "    print(torch.cumsum(torch.exp(net.mu),dim=0))\n",
    "    all_losses.append(loss.item())\n",
    "    trial_times.append(time.time() - trial_start_time)\n",
    "    final_mu_values.append(torch.cumsum(torch.exp(net.mu),dim=0).detach().cpu().numpy())\n",
    "\n",
    "    # Save filtered states\n",
    "    net.cpu()\n",
    "    observations_o=observations_o.cpu()\n",
    "    observations_o1=observations_o1.cpu()\n",
    "   \n",
    "\n",
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)\n",
    "\n",
    "# # Plot loss curve\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for trial_losses in all_losses:\n",
    "#     plt.plot(trial_losses, alpha=0.7)\n",
    "# plt.title('Loss Curve Across Trials')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.3446268, 2.002903 , 2.6074228, 3.6621232], dtype=float32),\n",
       " array([1.5046484, 2.3606641, 3.5296082, 6.69927  ], dtype=float32),\n",
       " array([1.5067197, 2.3625393, 3.5336719, 6.695287 ], dtype=float32),\n",
       " array([1.503427 , 2.360703 , 3.538041 , 6.7039757], dtype=float32),\n",
       " array([1.5040528, 2.3592958, 3.534512 , 6.7013855], dtype=float32),\n",
       " array([1.5031744, 2.356007 , 3.5280502, 6.705928 ], dtype=float32),\n",
       " array([1.5031457, 2.3608694, 3.5336156, 6.693484 ], dtype=float32),\n",
       " array([1.5047388, 2.3602157, 3.527163 , 6.702697 ], dtype=float32),\n",
       " array([1.5051916, 2.361664 , 3.5271795, 6.700492 ], dtype=float32),\n",
       " array([1.4989178, 2.3525648, 3.5273924, 6.6959195], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mu_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred1 = torch.load('DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Parameters for experiment\n",
    "batch_size = 100\n",
    "num_epochs = 10000\n",
    "n_trials = 10\n",
    "learning_rate = 0.01\n",
    "device='cuda'\n",
    "# Initialize result containers\n",
    "all_losses = []\n",
    "all_l1 = []\n",
    "all_l2 = []\n",
    "trial_times = []\n",
    "final_mu_values = []\n",
    "# Parameters for early stopping\n",
    "patience = 200000  # Number of epochs to wait for improvement\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial {trial + 1}/{n_trials}\")\n",
    "    trial_start_time = time.time()\n",
    "\n",
    "    net = Net().to(device)  # Initialize model\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.0001, total_iters=num_epochs)\n",
    "\n",
    "    net.train()\n",
    "    trial_losses = []\n",
    "    trial_l1 = []\n",
    "    trial_l2 = []\n",
    "    # Extract observations and underlying states\n",
    "    observations_o = [o for o, _, _, _ in pred1]\n",
    "    observations_o1 = [o for _, o, _, _ in pred1]\n",
    "    true_states = [t.numpy()[:, 0:1] for _, _, _, t in pred1]\n",
    "    true_states1 = [t.numpy()[:, 1:2] for _, _, _, t in pred1]\n",
    "    observations_o, m1 = pad_sequences(observations_o, padding_value=-1)\n",
    "    observations_o1, m2 = pad_sequences(observations_o1, padding_value=-1)\n",
    "    observations_o = observations_o.cuda()\n",
    "    observations_o1 = observations_o1.cuda()\n",
    "    m1 = m1.cuda()\n",
    "    m2 = m2.cuda()\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        net.t = 0  # Reset any time-dependent states\n",
    "\n",
    "        # Create random batch indices\n",
    "        loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        l1, l2, _ = net.training1(0, observations_o, observations_o1, m1, m2, 0.0)\n",
    "        loss -= (torch.mean(l1) + torch.mean(l2))\n",
    "\n",
    "        trial_losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Check early stopping\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model_state = net.state_dict()  # Save the best model state\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Save trial results\n",
    "    print(f\"Final Loss for Trial {trial + 1}: {loss.item()}\")\n",
    "    all_losses.append(best_loss)\n",
    "    trial_times.append(time.time() - trial_start_time)\n",
    "    final_mu_values.append(net.mu.detach().cpu().numpy())\n",
    "\n",
    "    # Load the best model state for evaluation\n",
    "    net.load_state_dict(best_model_state)\n",
    "\n",
    "    # Save filtered states\n",
    "    net.cpu()\n",
    "    observations_o = observations_o.cpu()\n",
    "    observations_o1 = observations_o1.cpu()\n",
    "    m1 = m1.cpu()\n",
    "    m2 = m2.cpu()\n",
    "    for i in range(0, batch_size):\n",
    "        o, o1, t, states = pred1[i]\n",
    "        o, o1 = o.to('cpu'), o1.to('cpu')\n",
    "        filtered_l1, filtered_l2 = net.state_filter(t, o, o1, 0.0)\n",
    "        trial_l1.append(torch.argmax(filtered_l1, dim=2)[0])\n",
    "        trial_l2.append(torch.argmax(filtered_l2, dim=2)[0])\n",
    "\n",
    "    all_l1.append(trial_l1)\n",
    "    all_l2.append(trial_l2)\n",
    "\n",
    "# Compute statistics across trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc): Linear(in_features=5, out_features=4, bias=False)\n",
       "  (fc1): Linear(in_features=5, out_features=4, bias=False)\n",
       "  (fc2): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (fc3): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (fc4): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (fc5): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (A1): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A2): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A3): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A4): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A5): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A6): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A7): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A8): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A9): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A10): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (lstm1): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm2): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm3): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm4): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trial_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589.8387451171875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(trial_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-408.9480895996094,\n",
       " -432.67340087890625,\n",
       " -431.3787841796875,\n",
       " -430.7692565917969,\n",
       " -431.385009765625,\n",
       " -429.46380615234375,\n",
       " -430.73284912109375,\n",
       " -429.91241455078125,\n",
       " -431.4179382324219,\n",
       " -431.98370361328125]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "Mean Loss (Final Epoch): 428.8665252685547, Std Loss: 6.6982929124516\n",
      "Mean Training Time: 2535.802258181572s, Std Training Time: 111.49345238290287s\n",
      "Final mu values (across trials): [[1.3446268 2.002903  2.6074228 3.6621232]\n",
      " [1.5046484 2.3606641 3.5296082 6.69927  ]\n",
      " [1.5067197 2.3625393 3.5336719 6.695287 ]\n",
      " [1.503427  2.360703  3.538041  6.7039757]\n",
      " [1.5040528 2.3592958 3.534512  6.7013855]\n",
      " [1.5031744 2.356007  3.5280502 6.705928 ]\n",
      " [1.5031457 2.3608694 3.5336156 6.693484 ]\n",
      " [1.5047388 2.3602157 3.527163  6.702697 ]\n",
      " [1.5051916 2.361664  3.5271795 6.700492 ]\n",
      " [1.4989178 2.3525648 3.5273924 6.6959195]]\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(\"Training Results:\")\n",
    "print(f\"Mean Loss (Final Epoch): {-mean_losses}, Std Loss: {std_losses}\")\n",
    "print(f\"Mean Training Time: {mean_trial_time}s, Std Training Time: {std_trial_time}s\")\n",
    "print(f\"Final mu values (across trials): {np.array(final_mu_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred1[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pred1[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State filtering MSE\n",
    "true_states = [t.numpy()[:, 0:1] for _, _, _, t in pred1]\n",
    "true_states1 = [t.numpy()[:, 1:2] for _, _, _, t in pred1]\n",
    "\n",
    "trial_mse_l1 = []\n",
    "trial_mse_l2 = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    mse_l1 = 0.0\n",
    "    mse_l2 = 0.0\n",
    "    total_states = 0\n",
    "\n",
    "    l1 = all_l1[trial]\n",
    "    l2 = all_l2[trial]\n",
    "\n",
    "    for filtered_l1, filtered_l2, ts, ts1 in zip(l1, l2, true_states, true_states1):\n",
    "        mse_l1 += (np.diag(filtered_l1.detach().numpy() == ts) ).sum()\n",
    "        # print(filtered_l1.shape)\n",
    "        # print(ts.shape)\n",
    "        mse_l2 += (np.diag(filtered_l2.detach().numpy() ==  ts1)).sum()\n",
    "        total_states += ts.shape[0]\n",
    "    # print(mse_l1)\n",
    "    # print(total_states)\n",
    "    \n",
    "\n",
    "    mse_l1 /= total_states\n",
    "    mse_l2 /= total_states\n",
    "\n",
    "    trial_mse_l1.append(mse_l1)\n",
    "    trial_mse_l2.append(mse_l2)\n",
    "\n",
    "# Calculate average error and standard deviation\n",
    "average_mse_l1 = np.mean(trial_mse_l1)\n",
    "std_mse_l1 = np.std(trial_mse_l1)\n",
    "\n",
    "average_mse_l2 = np.mean(trial_mse_l2)\n",
    "std_mse_l2 = np.std(trial_mse_l2)\n",
    "\n",
    "# Print results\n",
    "print(\"State Filtering MSE Results:\")\n",
    "print(f\"Average MSE for l1: {average_mse_l1:.4f}, Std Dev: {std_mse_l1:.4f}\")\n",
    "print(f\"Average MSE for l2: {average_mse_l2:.4f}, Std Dev: {std_mse_l2:.4f}\")\n",
    "\n",
    "# Print MSE for each trial\n",
    "for trial, (mse_l1, mse_l2) in enumerate(zip(trial_mse_l1, trial_mse_l2), 1):\n",
    "    print(f\"Trial {trial}: MSE l1 = {mse_l1:.4f}, MSE l2 = {mse_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mse_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_mse_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of parameters\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
