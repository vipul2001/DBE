{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)  # Set to any fixed integer\n",
    "\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)  # If using multiple GPUs\n",
    "import numpy as np\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix=torch.tensor([[0.9, 0.1, 0.0,0.0],\n",
    "        [0.00, 0.9, 0.1,0],\n",
    "        [0.0, 0.00, 0.9,.1],\n",
    "                      [0.0,0.0,0.0,1]], device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix1=torch.zeros(4,4,4)\n",
    "T_matrix1[0,:,:]=T_matrix+torch.eye(4,4)*-0.0\n",
    "T_matrix1[1,:,:]=T_matrix+torch.eye(4,4)*-0.3\n",
    "T_matrix1[2,:,:]=T_matrix+torch.eye(4,4)*-0.5\n",
    "T_matrix1[3,:,:]=T_matrix+torch.eye(4,4)*-0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix1=T_matrix1/torch.sum(T_matrix1, 2).reshape(4,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9000, 0.1000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9000, 0.1000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.8571, 0.1429, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8571, 0.1429, 0.0000],\n",
       "         [0.0000, 0.0000, 0.8571, 0.1429],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.8000, 0.2000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8000, 0.2000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.8000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.6667, 0.3333, 0.0000, 0.0000],\n",
       "         [0.0000, 0.6667, 0.3333, 0.0000],\n",
       "         [0.0000, 0.0000, 0.6667, 0.3333],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9000, 0.1000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9000, 0.1000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "\n",
    "O_matrix_mean=torch.tensor([1.5,2.5,3.5,5.5]).to(device)\n",
    "O_matrix_std=torch.tensor([1.1,1.2,1.3,1.4]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the joint state space for two units (4 states each)\n",
    "joint_states = [(i, j) for i in range(4) for j in range(4)]\n",
    "num_joint_states = len(joint_states)\n",
    "# Sort the joint states based on the sum of values in each tuple\n",
    "joint_states = sorted(joint_states, key=lambda x: sum(x))\n",
    "# Example: Define a 4x4 joint transition matrix P((s1, s2) -> (s1', s2'))\n",
    "P_joint = np.array([\n",
    "    # Each row corresponds to a joint state, each column to the next joint state\n",
    "    [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],  # (0,0) -> various states\n",
    "    [0.3, 0.3, 0.1, 0.1, 0.07, 0.05, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (0,1)\n",
    "    [0.2, 0.2, 0.3, 0.1, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,2)\n",
    "    [0.1, 0.1, 0.2, 0.4, 0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,3)\n",
    "    [0.3, 0.2, 0.1, 0.1, 0.2, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (1,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.3, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0],  # (1,1)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.4, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01, 0.0, 0.0],  # (1,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.2, 0.1, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0],  # (1,3)\n",
    "    [0.3, 0.1, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01],  # (2,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.1, 0.4, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01],  # (2,1)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.05, 0.05, 0.3, 0.05, 0.02, 0.02, 0.01, 0.01],  # (2,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.1, 0.3, 0.05, 0.05, 0.02, 0.02],  # (2,3)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.3, 0.1, 0.05, 0.05],  # (3,0)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.3, 0.05, 0.1],  # (3,1)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05, 0.1, 0.4, 0.2],  # (3,2)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # (3,3)\n",
    "])\n",
    "\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i):\n",
    "        P_joint[i, j] = 0\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i+5,16):\n",
    "        P_joint[i, j] = 0\n",
    "\n",
    "P_joint=P_joint+np.eye(16,16)*0.5\n",
    "# Normalize each row so the sum of probabilities equals 1\n",
    "P_joint = P_joint / P_joint.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Check if the rows sum to 1\n",
    "row_sums = P_joint.sum(axis=1)\n",
    "print(row_sums)  # Should all be close to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# torch.manual_seed(42)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_19232\\4018448443.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pred1 = torch.load('DATA_NON_LINEAR.pth')\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:48: RuntimeWarning: divide by zero encountered in log\n",
      "  return f_raw(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b34d5904f043d3ab23be363802c1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c434a03343604a11b02b0af909651ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM for 'o': Mean Likelihood = -744.6862285162849, Std = 35.965715920520395, Filtration Error = 0.9705988023952096\n",
      "HMM for 'o1': Mean Likelihood = -750.1631665662386, Std = 17.65318998118975, Filtration Error = 0.2392814371257485\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load data\n",
    "pred1 = torch.load('DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Extract observations and underlying states\n",
    "observations_o = [o.numpy().reshape(-1, 1) for o, _, _,_ in pred1]\n",
    "observations_o1 = [o.numpy().reshape(-1, 1) for _, o, _,_ in pred1]\n",
    "true_states = [t.numpy()[:,0:1] for _, _, _,t in pred1]\n",
    "true_states1 = [t.numpy()[:,1:2] for _, _, _,t in pred1]\n",
    "\n",
    "import numpy as np\n",
    "import ssm\n",
    "\n",
    "def train_hmm_and_evaluate(observations, n_components=4, obs_type=\"gaussian\", n_iter=100):\n",
    "    \"\"\"\n",
    "    Train a Hidden Semi-Markov Model (HSMM) on the provided observations.\n",
    "\n",
    "    Parameters:\n",
    "    - observations: List of sequences of observations (each sequence should be a 2D numpy array).\n",
    "    - n_components: The number of states in the HSMM.\n",
    "    - obs_type: Type of observation model (\"gaussian\", \"bernoulli\", etc.).\n",
    "    - n_iter: Number of EM iterations for training.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained HSMM model.\n",
    "    - mean_likelihood: Mean log-likelihood of the observation sequences.\n",
    "    - std_likelihood: Standard deviation of log-likelihoods.\n",
    "    - filtered_states: List of most likely states for each observation sequence.\n",
    "    \"\"\"\n",
    "    # Flatten the data and create lengths array\n",
    "    lengths = [len(seq) for seq in observations]\n",
    "    X = np.concatenate(observations, axis=0)\n",
    "\n",
    "    # Initialize HSMM\n",
    "    hsmm = ssm.HSMM(K=n_components, D=X.shape[1], observations=obs_type,transition_kwargs={'r_min' : 1, 'r_max' : 3})\n",
    "\n",
    "    # Fit the HSMM using the EM algorithm\n",
    "    hsmm.fit(X, method=\"em\")\n",
    "\n",
    "    # Calculate log-likelihoods for each sequence\n",
    "    log_likelihoods = [hsmm.log_likelihood(seq) for seq in observations]\n",
    "    mean_likelihood = np.mean(log_likelihoods)\n",
    "    std_likelihood = np.std(log_likelihoods)\n",
    "\n",
    "    # Get filtered states for each sequence\n",
    "    filtered_states = [hsmm.most_likely_states(seq) for seq in observations]\n",
    "\n",
    "    return hsmm, mean_likelihood, std_likelihood, filtered_states\n",
    "\n",
    "\n",
    "# Train HMMs for o and o1 observations\n",
    "model_o, mean_likelihood_o, std_likelihood_o, filtered_states_o = train_hmm_and_evaluate(observations_o)\n",
    "model_o1, mean_likelihood_o1, std_likelihood_o1, filtered_states_o1 = train_hmm_and_evaluate(observations_o1)\n",
    "\n",
    "# Calculate state filtration errors\n",
    "def calculate_filtration_error(filtered_states, true_states):\n",
    "    total_errors = 0\n",
    "    total_states = 0\n",
    "    for filtered, true in zip(filtered_states, true_states):\n",
    "        # print(((filtered == true)).shape)\n",
    "        total_errors +=  (np.diag(filtered == true)).sum()\n",
    "        total_states += len(true)\n",
    "        # print(total_states)\n",
    "    return total_errors / total_states\n",
    "\n",
    "error_o = calculate_filtration_error(filtered_states_o, true_states)\n",
    "error_o1 = calculate_filtration_error(filtered_states_o1, true_states1)\n",
    "\n",
    "# Print results\n",
    "print(f\"HMM for 'o': Mean Likelihood = {mean_likelihood_o}, Std = {std_likelihood_o}, Filtration Error = {error_o}\")\n",
    "print(f\"HMM for 'o1': Mean Likelihood = {mean_likelihood_o1}, Std = {std_likelihood_o1}, Filtration Error = {error_o1}\")\n",
    "# print(model_o.means_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rearrange_states(filtered_states, hmm_means):\n",
    "    \"\"\"\n",
    "    Rearranges states based on the order of HMM means.\n",
    "    \n",
    "    Args:\n",
    "        filtered_states (list of np.ndarray): List of filtered states.\n",
    "        hmm_means (np.ndarray): The means of the Gaussian HMM components.\n",
    "        \n",
    "    Returns:\n",
    "        list of np.ndarray: Rearranged filtered states.\n",
    "    \"\"\"\n",
    "    # Get the new state order by sorting the means\n",
    "    sorted_indices = np.argsort(hmm_means.flatten())\n",
    "    state_mapping = {old: new for new, old in enumerate(sorted_indices)}\n",
    "\n",
    "    # Rearrange states in the filtered results\n",
    "    rearranged_states = []\n",
    "    for states in filtered_states:\n",
    "        rearranged_states.append(np.vectorize(state_mapping.get)(states))\n",
    "    \n",
    "    return rearranged_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26de5f4c4dc44bb19db194794cb7d5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0972d4999ded421ca0f9a23f907cfefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335ee4e9376b449d9f762d6667db5286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4b2f7b0932493f874c8bcb4e60ef40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ac86c6839c4db1a8abfe6da941942a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9edd7b4f7bc4091a66b8c623de580cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57859cb07cf24f2c81da2c2825cb084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae9c93011ae4233a1ab9de25ee1e6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37c2b1511dd4d0c89df8d09aa643af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f18065db094ad1a1fdc7a7d251187c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f5fbc26c514ec49932283c5962bd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361024ad1e7549629f3e84c579ac814f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc32c16215264c72b3d44c8cbf055d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae273b0a580b428fa91738e5c4685eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a498cef914a4e048907e3308f91b785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426b410d9f004fa4b3ff73018abf8561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f630b36fdf884acebec1f89271b490d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026f530a798e4ad4b2229ce4ed46a6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedb205f0d3b458193379933ff3f73a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(501, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fabf95e8df2423d8c2037812608193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM for 'o':\n",
      "Mean Likelihood: -743.5223545862225, Std: 3.0303698226524967\n",
      "Mean Filtration Error: 0.5857445109780439, Std: 0.1949452260630566\n",
      "Mean Computation Time: 17.01154770851135s, Std: 4.727771005551559s\n",
      "\n",
      "HMM for 'o1':\n",
      "Mean Likelihood: -779.7434880802864, Std: 29.568845874881443\n",
      "Mean Filtration Error: 0.7860479041916167, Std: 0.20795083463956646\n",
      "Mean Computation Time: 13.128303146362304s, Std: 2.725431872281021s\n"
     ]
    }
   ],
   "source": [
    "# Repeat training multiple times and collect metrics\n",
    "import time\n",
    "n_repeats = 10\n",
    "results_o = []\n",
    "results_o1 = []\n",
    "time_o = []\n",
    "time_o1 = []\n",
    "\n",
    "for _ in range(n_repeats):\n",
    "    start_time = time.time()\n",
    "    model_o, mean_likelihood_o, std_likelihood_o, filtered_states_o = train_hmm_and_evaluate(observations_o)\n",
    "    hmm_means = model_o.observations.mus\n",
    "    filtered_states_o = rearrange_states(filtered_states_o, hmm_means)\n",
    "    print(filtered_states_o[0].shape)\n",
    "    print(true_states[0].shape)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    error_o = calculate_filtration_error(filtered_states_o, true_states)\n",
    "    results_o.append((mean_likelihood_o, std_likelihood_o, error_o))\n",
    "    time_o.append(elapsed_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_o1, mean_likelihood_o1, std_likelihood_o1, filtered_states_o1 = train_hmm_and_evaluate(observations_o1)\n",
    "    hmm_means = model_o1.observations.mus\n",
    "    filtered_states_o1 = rearrange_states(filtered_states_o1, hmm_means)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    error_o1 = calculate_filtration_error(filtered_states_o1, true_states1)\n",
    "    results_o1.append((mean_likelihood_o1, std_likelihood_o1, error_o1))\n",
    "    time_o1.append(elapsed_time)\n",
    "\n",
    "# Calculate mean and standard deviation for metrics\n",
    "metrics_o = np.array(results_o)\n",
    "metrics_o1 = np.array(results_o1)\n",
    "\n",
    "mean_metrics_o = metrics_o.mean(axis=0)\n",
    "std_metrics_o = metrics_o.std(axis=0)\n",
    "\n",
    "mean_metrics_o1 = metrics_o1.mean(axis=0)\n",
    "std_metrics_o1 = metrics_o1.std(axis=0)\n",
    "\n",
    "# Calculate mean and standard deviation for computation time\n",
    "mean_time_o = np.mean(time_o)\n",
    "std_time_o = np.std(time_o)\n",
    "\n",
    "mean_time_o1 = np.mean(time_o1)\n",
    "std_time_o1 = np.std(time_o1)\n",
    "\n",
    "# Print results\n",
    "print(\"HMM for 'o':\")\n",
    "print(f\"Mean Likelihood: {mean_metrics_o[0]}, Std: {std_metrics_o[0]}\")\n",
    "print(f\"Mean Filtration Error: {mean_metrics_o[2]}, Std: {std_metrics_o[2]}\")\n",
    "print(f\"Mean Computation Time: {mean_time_o}s, Std: {std_time_o}s\\n\")\n",
    "\n",
    "print(\"HMM for 'o1':\")\n",
    "print(f\"Mean Likelihood: {mean_metrics_o1[0]}, Std: {std_metrics_o1[0]}\")\n",
    "print(f\"Mean Filtration Error: {mean_metrics_o1[2]}, Std: {std_metrics_o1[2]}\")\n",
    "print(f\"Mean Computation Time: {mean_time_o1}s, Std: {std_time_o1}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM for 'TOTAL':\n",
      "Mean Likelihood: -1523.265842666509, Std: 30.574893517405165\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"HMM for 'TOTAL':\")\n",
    "print(f\"Mean Likelihood: {(metrics_o1+metrics_o).mean(axis=0)[0]}, Std: {(metrics_o1+metrics_o).std(axis=0)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_o = [np.concatenate([o.numpy().reshape(-1, 1),o1.numpy().reshape(-1, 1)], axis=1) for o, o1, _,_ in pred1]\n",
    "# observations_o = [np.concatenate([o.numpy().reshape(-1, 1),o1.numpy().reshape(-1, 1)], axis=1) for o, o1, _,_ in pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e78bd93fb0d484c934955384cc71eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61938874d78b4521b9eeb4e6e156cf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdaa180ae7748cc8542a58dabf67ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5762aeb621423eb9d21ed770223e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ea50d1b8214614b4b3a21e1b73a071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cb15f23a73401dbcbf9477234a4aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce9d907a8844cafa9d6ea894885d01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7b9147f92844d39979ffc34269d928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d0c1687eff4a72b4e03db3deb3a7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f7b988ece34069aedbad7b54a606b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM for 'o':\n",
      "Mean Likelihood: -1647.6870958938198, Std: 11.117752825354804\n",
      "Mean Filtration Error: 0.0, Std: 0.0\n",
      "Mean Computation Time: 14.841072130203248s, Std: 1.983788017074653s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat training multiple times and collect metrics\n",
    "import time\n",
    "n_repeats = 10\n",
    "results_o = []\n",
    "results_o1 = []\n",
    "time_o = []\n",
    "time_o1 = []\n",
    "\n",
    "for _ in range(n_repeats):\n",
    "    start_time = time.time()\n",
    "    model_o, mean_likelihood_o, std_likelihood_o, filtered_states_o = train_hmm_and_evaluate(observations_o, n_components=4)\n",
    "    hmm_means = model_o.observations.mus\n",
    "    filtered_states_o = rearrange_states(filtered_states_o, hmm_means)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    error_o = 0\n",
    "    results_o.append((mean_likelihood_o, std_likelihood_o, error_o))\n",
    "    time_o.append(elapsed_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "# Calculate mean and standard deviation for metrics\n",
    "metrics_o = np.array(results_o)\n",
    "\n",
    "\n",
    "mean_metrics_o = metrics_o.mean(axis=0)\n",
    "std_metrics_o = metrics_o.std(axis=0)\n",
    "\n",
    "\n",
    "# Calculate mean and standard deviation for computation time\n",
    "mean_time_o = np.mean(time_o)\n",
    "std_time_o = np.std(time_o)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"HMM for 'o':\")\n",
    "print(f\"Mean Likelihood: {mean_metrics_o[0]}, Std: {std_metrics_o[0]}\")\n",
    "print(f\"Mean Filtration Error: {mean_metrics_o[2]}, Std: {std_metrics_o[2]}\")\n",
    "print(f\"Mean Computation Time: {mean_time_o}s, Std: {std_time_o}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3964f77091504098bf2fc9fbd22da55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310bf78122fa4b3090c3fe91f2d6aea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e36c16623e342a4875572bb96557fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202947af1ea54eb28da918c96a49d787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3be49a00f02475f801b191c5fc1ae81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481ef6f5a22b428490df1afb1a08a8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d27ff9d4d374ac1a262f9fdb0236bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f85920b93c2484e96a47d7e17c46ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f5b8d053004c42afb9ea36e5a13fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06498d5cd57a451098e7243b3a8e999e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM for 'o':\n",
      "Mean Likelihood: -1503.4115712711325, Std: 18.22434081716899\n",
      "Mean Filtration Error: 0.0, Std: 0.0\n",
      "Mean Computation Time: 38.48651461601257s, Std: 5.32357666008662s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat training multiple times and collect metrics\n",
    "import time\n",
    "n_repeats = 10\n",
    "results_o = []\n",
    "results_o1 = []\n",
    "time_o = []\n",
    "time_o1 = []\n",
    "\n",
    "for _ in range(n_repeats):\n",
    "    start_time = time.time()\n",
    "    model_o, mean_likelihood_o, std_likelihood_o, filtered_states_o = train_hmm_and_evaluate(observations_o, n_components=8)\n",
    "    hmm_means = model_o.observations.mus\n",
    "    filtered_states_o = rearrange_states(filtered_states_o, hmm_means)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    error_o = 0\n",
    "    results_o.append((mean_likelihood_o, std_likelihood_o, error_o))\n",
    "    time_o.append(elapsed_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "# Calculate mean and standard deviation for metrics\n",
    "metrics_o = np.array(results_o)\n",
    "\n",
    "\n",
    "mean_metrics_o = metrics_o.mean(axis=0)\n",
    "std_metrics_o = metrics_o.std(axis=0)\n",
    "\n",
    "\n",
    "# Calculate mean and standard deviation for computation time\n",
    "mean_time_o = np.mean(time_o)\n",
    "std_time_o = np.std(time_o)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"HMM for 'o':\")\n",
    "print(f\"Mean Likelihood: {mean_metrics_o[0]}, Std: {std_metrics_o[0]}\")\n",
    "print(f\"Mean Filtration Error: {mean_metrics_o[2]}, Std: {std_metrics_o[2]}\")\n",
    "print(f\"Mean Computation Time: {mean_time_o}s, Std: {std_time_o}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e1403aba8544f18b93949cba5ab683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\documents\\ssm\\ssm\\transitions.py:370: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"\n",
      "c:\\users\\administrator\\documents\\ssm\\ssm\\transitions.py:505: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_repeats):\n\u001b[0;32m     10\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 11\u001b[0m     model_o, mean_likelihood_o, std_likelihood_o, filtered_states_o \u001b[38;5;241m=\u001b[39m train_hmm_and_evaluate(observations_o, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     12\u001b[0m     hmm_means \u001b[38;5;241m=\u001b[39m model_o\u001b[38;5;241m.\u001b[39mobservations\u001b[38;5;241m.\u001b[39mmus\n\u001b[0;32m     13\u001b[0m     filtered_states_o \u001b[38;5;241m=\u001b[39m rearrange_states(filtered_states_o, hmm_means)\n",
      "Cell \u001b[1;32mIn[11], line 41\u001b[0m, in \u001b[0;36mtrain_hmm_and_evaluate\u001b[1;34m(observations, n_components, obs_type, n_iter)\u001b[0m\n\u001b[0;32m     38\u001b[0m hsmm \u001b[38;5;241m=\u001b[39m ssm\u001b[38;5;241m.\u001b[39mHSMM(K\u001b[38;5;241m=\u001b[39mn_components, D\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], observations\u001b[38;5;241m=\u001b[39mobs_type,transition_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_min\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_max\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m3\u001b[39m})\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Fit the HSMM using the EM algorithm\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m hsmm\u001b[38;5;241m.\u001b[39mfit(X, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mem\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Calculate log-likelihoods for each sequence\u001b[39;00m\n\u001b[0;32m     44\u001b[0m log_likelihoods \u001b[38;5;241m=\u001b[39m [hsmm\u001b[38;5;241m.\u001b[39mlog_likelihood(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m observations]\n",
      "File \u001b[1;32mc:\\users\\administrator\\documents\\ssm\\ssm\\util.py:111\u001b[0m, in \u001b[0;36mensure_args_are_lists.<locals>.wrapper\u001b[1;34m(self, datas, inputs, masks, tags, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    109\u001b[0m     tags \u001b[38;5;241m=\u001b[39m [tags]\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, datas, inputs\u001b[38;5;241m=\u001b[39minputs, masks\u001b[38;5;241m=\u001b[39mmasks, tags\u001b[38;5;241m=\u001b[39mtags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\administrator\\documents\\ssm\\ssm\\hmm.py:816\u001b[0m, in \u001b[0;36mHSMM.fit\u001b[1;34m(self, datas, inputs, masks, tags, verbose, method, initialize, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initialize:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize(datas, inputs\u001b[38;5;241m=\u001b[39minputs, masks\u001b[38;5;241m=\u001b[39mmasks, tags\u001b[38;5;241m=\u001b[39mtags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _fitting_methods[method](datas, inputs\u001b[38;5;241m=\u001b[39minputs, masks\u001b[38;5;241m=\u001b[39mmasks, tags\u001b[38;5;241m=\u001b[39mtags, verbose \u001b[38;5;241m=\u001b[39m verbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\administrator\\documents\\ssm\\ssm\\hmm.py:794\u001b[0m, in \u001b[0;36mHSMM._fit_em\u001b[1;34m(self, datas, inputs, masks, tags, verbose, num_iters, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# M step: maximize expected log joint wrt parameters\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state_distn\u001b[38;5;241m.\u001b[39mm_step(expectations, datas, inputs, masks, tags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransitions\u001b[38;5;241m.\u001b[39mm_step(expectations, datas, inputs, masks, tags, samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations\u001b[38;5;241m.\u001b[39mm_step(expectations, datas, inputs, masks, tags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# Store progress\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\administrator\\documents\\ssm\\ssm\\transitions.py:666\u001b[0m, in \u001b[0;36mNegativeBinomialSemiMarkovTransitions.m_step\u001b[1;34m(self, expectations, datas, inputs, masks, tags, samples, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m states, durations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(np\u001b[38;5;241m.\u001b[39mconcatenate, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[rle(z_smpl) \u001b[38;5;28;01mfor\u001b[39;00m z_smpl \u001b[38;5;129;01min\u001b[39;00m samples]))\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrs[k], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mps[k] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 666\u001b[0m         fit_negative_binomial_integer_r(durations[states \u001b[38;5;241m==\u001b[39m k], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr_min, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr_max)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# Reset the transition matrix\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transition_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\administrator\\documents\\ssm\\ssm\\regression.py:522\u001b[0m, in \u001b[0;36mfit_negative_binomial_integer_r\u001b[1;34m(xs, r_min, r_max)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_negative_binomial_integer_r\u001b[39m(xs, r_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, r_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Fit a negative binomial distribution NB(r, p) to data xs,\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    under the constraint that the shape r is an integer.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    The durations are 1 + a negative binomial random variable.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(xs, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m xs\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m xs\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    523\u001b[0m     xs \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    524\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(xs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:45\u001b[0m, in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "# Repeat training multiple times and collect metrics\n",
    "import time\n",
    "n_repeats = 10\n",
    "results_o = []\n",
    "results_o1 = []\n",
    "time_o = []\n",
    "time_o1 = []\n",
    "\n",
    "for _ in range(n_repeats):\n",
    "    start_time = time.time()\n",
    "    model_o, mean_likelihood_o, std_likelihood_o, filtered_states_o = train_hmm_and_evaluate(observations_o, n_components=16)\n",
    "    hmm_means = model_o.observations.mus\n",
    "    filtered_states_o = rearrange_states(filtered_states_o, hmm_means)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    error_o = 0\n",
    "    results_o.append((mean_likelihood_o, std_likelihood_o, error_o))\n",
    "    time_o.append(elapsed_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "# Calculate mean and standard deviation for metrics\n",
    "metrics_o = np.array(results_o)\n",
    "\n",
    "\n",
    "mean_metrics_o = metrics_o.mean(axis=0)\n",
    "std_metrics_o = metrics_o.std(axis=0)\n",
    "\n",
    "\n",
    "# Calculate mean and standard deviation for computation time\n",
    "mean_time_o = np.mean(time_o)\n",
    "std_time_o = np.std(time_o)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"HMM for 'o':\")\n",
    "print(f\"Mean Likelihood: {mean_metrics_o[0]}, Std: {std_metrics_o[0]}\")\n",
    "print(f\"Mean Filtration Error: {mean_metrics_o[2]}, Std: {std_metrics_o[2]}\")\n",
    "print(f\"Mean Computation Time: {mean_time_o}s, Std: {std_time_o}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
