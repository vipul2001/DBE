{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([[0.9900, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9900, 0.0100, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9900, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2756,  2.3558,  4.6775,  3.6275,  1.0345,  3.6676,  0.6997,  2.3232,\n",
       "          2.6754,  6.9749,  7.1938,  6.9952,  5.6103,  1.9316,  4.3834,  2.5275,\n",
       "          3.6437,  3.2761,  4.2493,  3.6857,  5.6159,  4.5453,  2.1995,  2.2413,\n",
       "          7.1645,  6.3367,  6.1257,  5.7387,  3.4800,  5.8359,  5.8227,  5.3550,\n",
       "          6.4102,  6.8119]),\n",
       " tensor([ 1.1799,  3.5449,  0.3162, -0.3709,  1.5725,  0.1408,  4.3338,  5.0225,\n",
       "          4.6176,  0.2655, -0.0796,  1.2993,  0.2930,  7.6408,  7.3216,  6.6882,\n",
       "          7.2462,  6.4861,  6.8000,  7.7768,  7.3167,  8.0311,  9.2748,  8.5925,\n",
       "          6.3070,  8.1663,  8.4904,  7.5853,  8.8961,  5.1212,  5.6205,  9.0888,\n",
       "          7.7245,  7.8674]),\n",
       " 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the joint state space for two units (4 states each)\n",
    "joint_states = [(i, j) for i in range(4) for j in range(4)]\n",
    "num_joint_states = len(joint_states)\n",
    "# Sort the joint states based on the sum of values in each tuple\n",
    "joint_states = sorted(joint_states, key=lambda x: sum(x))\n",
    "# Example: Define a 4x4 joint transition matrix P((s1, s2) -> (s1', s2'))\n",
    "P_joint = np.array([\n",
    "    # Each row corresponds to a joint state, each column to the next joint state\n",
    "    [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],  # (0,0) -> various states\n",
    "    [0.3, 0.3, 0.1, 0.1, 0.07, 0.05, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (0,1)\n",
    "    [0.2, 0.2, 0.3, 0.1, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,2)\n",
    "    [0.1, 0.1, 0.2, 0.4, 0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,3)\n",
    "    [0.3, 0.2, 0.1, 0.1, 0.2, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (1,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.3, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0],  # (1,1)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.4, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01, 0.0, 0.0],  # (1,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.2, 0.1, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0],  # (1,3)\n",
    "    [0.3, 0.1, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01],  # (2,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.1, 0.4, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01],  # (2,1)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.05, 0.05, 0.3, 0.05, 0.02, 0.02, 0.01, 0.01],  # (2,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.1, 0.3, 0.05, 0.05, 0.02, 0.02],  # (2,3)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.3, 0.1, 0.05, 0.05],  # (3,0)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.3, 0.05, 0.1],  # (3,1)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05, 0.1, 0.4, 0.2],  # (3,2)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # (3,3)\n",
    "])\n",
    "\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i):\n",
    "        P_joint[i, j] = 0\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i+5,16):\n",
    "        P_joint[i, j] = 0\n",
    "\n",
    "P_joint=P_joint+np.eye(16,16)*0.8\n",
    "# Normalize each row so the sum of probabilities equals 1\n",
    "P_joint = P_joint / P_joint.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Check if the rows sum to 1\n",
    "row_sums = P_joint.sum(axis=1)\n",
    "print(row_sums)  # Should all be close to 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P_joint\n",
    "\n",
    "\n",
    "\n",
    "T_matrix=torch.tensor([[0.99, 0.01, 0.0,0.0],\n",
    "        [0.00, 0.99, 0.01,0],\n",
    "        [0.0, 0.00, 0.99,.01],\n",
    "                      [0.0,0.0,0.0,1]], device=device) \n",
    "\n",
    "T_matrix1=torch.zeros(4,4,4)\n",
    "T_matrix1[0,:,:]=T_matrix+torch.eye(4,4)*-0.0\n",
    "T_matrix1[1,:,:]=T_matrix+torch.eye(4,4)*-0.3\n",
    "T_matrix1[2,:,:]=T_matrix+torch.eye(4,4)*-0.5\n",
    "T_matrix1[3,:,:]=T_matrix+torch.eye(4,4)*-0.7\n",
    "\n",
    "T_matrix1=T_matrix1/torch.sum(T_matrix1, 2).reshape(4,4,1)\n",
    "\n",
    "T_matrix1\n",
    "\n",
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "\n",
    "O_matrix_mean=torch.tensor([1.5,3.5,5.5,7.5]).to(device)\n",
    "O_matrix_std=torch.tensor([1.0,1.0,1.0,1.0]).to(device)\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)\n",
    "\n",
    "\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "def simulate_HMM(T_matrix_1,O_matrix,x,t):\n",
    "    x=(0,0)\n",
    "    current_state_idx = joint_states.index(x)\n",
    "    states=[]\n",
    "    t=0\n",
    "    o=[]\n",
    "    o1=[]\n",
    "#     o_1=torch.matmul(x.to(device),O_matrix.to(device))\n",
    "# #         print(o_1)\n",
    "    o.append(Normal(O_matrix_mean[x[0]],1).sample().to(device))\n",
    "    o1.append(Normal(O_matrix_mean[x[1]],1).sample().to(device))\n",
    "    t=1\n",
    "    h=torch.tensor([1,0,0,0.0])\n",
    "    states.append(x)\n",
    "    for i in range(1,5000):\n",
    "#         print(i)\n",
    "        # print(states)\n",
    "        t+=1\n",
    "        p = P_joint[current_state_idx]\n",
    "        # print(current_state_idx)\n",
    "        # Choose the next joint state based on the current transition probabilities\n",
    "        next_state_idx = np.random.choice(range(num_joint_states), p=p)\n",
    "        next_state = joint_states[next_state_idx]\n",
    "        x=next_state\n",
    "        # x[0]=x1.item()\n",
    "        # x[1]=x2.item()\n",
    "        states.append(x)\n",
    "        # print(x[0])\n",
    "        # print(alpha)\n",
    "        o_1,o_2 = MultivariateNormal(torch.stack([O_matrix_mean[x[0]], O_matrix_mean[x[1]]]), \n",
    "                                     torch.tensor([[1, 0.0],\n",
    "                              [0.0, 1]])).sample().t().to(device)\n",
    "        o.append(o_1)\n",
    "        o1.append(o_2)\n",
    "        current_state_idx=next_state_idx\n",
    "\n",
    "        \n",
    "        t1=t\n",
    "        \n",
    "        if x[0]==3 and x[1]==3:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    o=torch.tensor(o).to(device)\n",
    "    o1=torch.tensor(o1).to(device)\n",
    "    return o,o1,t\n",
    "\n",
    "o=simulate_HMM(T_matrix,O_matrix_mean,torch.tensor([1.0,0,0.0]),1000)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cc766b4e30>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "# plt.plot(o[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cc7ea679e0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "plt.plot(o[1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred1=[]\n",
    "# for i in range(0, 100):\n",
    "#             pred1.append(simulate_HMM(T_matrix, O_matrix_mean, s_0, 1))\n",
    "\n",
    "# torch.save(pred1, 'DATA_NON_LINEAR.pth')\n",
    "\n",
    "# print(\"pred1 list saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MAIN MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ATTENTION(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=4\n",
    "        self.num_states=4\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K, V, t1):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.tanh(self.fc_1(attn_output))+(t1))   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=300):\n",
    "        super().__init__()\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "        \n",
    "        # self.P[:, :, 0::2] = torch.cos(X)\n",
    "        # self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "\n",
    "\n",
    "class ATTENTION1(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION1, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=4\n",
    "        self.num_states=4\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K,V):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.leaky_relu(self.fc_1(attn_output))+ V )   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(Net, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=4\n",
    "        num_hiddens=4\n",
    "        self.num_states=4\n",
    "        self.s_0 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.s_01 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu1 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.sigma =nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "        self.sigma1 = nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        max_len=300\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc1 = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc2 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc3 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "        self.A1=ATTENTION()\n",
    "        self.A2=ATTENTION()\n",
    "        self.A3=ATTENTION()\n",
    "        self.A4=ATTENTION()\n",
    "        self.A5=ATTENTION()\n",
    "        self.A6=ATTENTION()\n",
    "        self.A7=ATTENTION()\n",
    "        self.A8=ATTENTION()\n",
    "        self.A9=ATTENTION()\n",
    "        self.A10=ATTENTION()\n",
    "\n",
    "        # LSTM Encoder\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm3 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm4 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        \n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(hidden_dim, 0)\n",
    "    def forward(self,  t, pred,pred1, prob=0.3):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def training1(self,  t, pred,pred1,m1,m2, prob=0.0):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        #pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        #pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            #print(o_1.shape)\n",
    "            #print(new_pred[:,:,i].shape)\n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        #mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        #replacement = torch.full_like(pred, -1.0)\n",
    "        #pred = pred * (1 - mask) + replacement * mask\n",
    "        #pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float().cuda()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states)).cuda()\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states)).cuda()\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1*m1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1*m2, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def state_filter(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred_1, pred1_1\n",
    "        \n",
    "    def state_filter1(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "        #     pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "        #     pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        # pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        # pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred, pred1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(Net, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=4\n",
    "        num_hiddens=4\n",
    "        self.num_states=4\n",
    "        self.s_0 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.s_01 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu1 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.sigma =nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "        self.sigma1 = nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        max_len=300\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc1 = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc2 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc3 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "        self.A1=ATTENTION()\n",
    "        self.A2=ATTENTION()\n",
    "        self.A3=ATTENTION()\n",
    "        self.A4=ATTENTION()\n",
    "        self.A5=ATTENTION()\n",
    "        self.A6=ATTENTION()\n",
    "        self.A7=ATTENTION()\n",
    "        self.A8=ATTENTION()\n",
    "        self.A9=ATTENTION()\n",
    "        self.A10=ATTENTION()\n",
    "\n",
    "        # LSTM Encoder\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm3 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm4 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        \n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(hidden_dim, 0)\n",
    "    def forward(self,  t, pred,pred1, prob=0.3):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def training1(self,  t, pred,pred1,m1,m2, prob=0.0):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        #pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        #pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            #print(o_1.shape)\n",
    "            #print(new_pred[:,:,i].shape)\n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        #mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        #replacement = torch.full_like(pred, -1.0)\n",
    "        #pred = pred * (1 - mask) + replacement * mask\n",
    "        #pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float().cuda()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states)).cuda()\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states)).cuda()\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1*m1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1*m2, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def state_filter(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "       \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred_1, pred1_1\n",
    "        \n",
    "    def state_filter1(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "        #     pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "        #     pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        # pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        # pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred, pred1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with a padding value.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = torch.full((len(sequences), max_length), padding_value, dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "    \n",
    "    return padded_sequences, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n",
    "\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=(e2-e1)**2\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26236\\132555617.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pred1 = torch.load('DATA_NON_LINEAR.pth')\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26236\\2057340665.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26236\\1707911684.py:222: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26236\\1707911684.py:223: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498.321533203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26236\\1707911684.py:386: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26236\\1707911684.py:387: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2/10\n",
      "1490.232666015625\n",
      "Trial 3/10\n",
      "1489.595947265625\n",
      "Trial 4/10\n",
      "1487.5810546875\n",
      "Trial 5/10\n",
      "1489.57373046875\n",
      "Trial 6/10\n",
      "1500.76025390625\n",
      "Trial 7/10\n",
      "1497.5556640625\n",
      "Trial 8/10\n",
      "1489.1982421875\n",
      "Trial 9/10\n",
      "1499.416259765625\n",
      "Trial 10/10\n",
      "1499.774658203125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "pred1 = torch.load('DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Parameters for experiment\n",
    "batch_size = 100\n",
    "num_epochs = 1000\n",
    "n_trials = 10\n",
    "learning_rate = 0.001\n",
    "device='cuda'\n",
    "# Initialize result containers\n",
    "all_losses = []\n",
    "all_l1 = []\n",
    "all_l2 = []\n",
    "trial_times = []\n",
    "final_mu_values = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial {trial + 1}/{n_trials}\")\n",
    "    trial_start_time = time.time()\n",
    "\n",
    "    net = Net().to(device)  # Initialize model\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=1.0, total_iters=num_epochs)\n",
    "\n",
    "    net.train()\n",
    "    trial_losses = []\n",
    "    trial_l1 = []\n",
    "    trial_l2 = []\n",
    "    # Extract observations and underlying states\n",
    "    observations_o = [o for o, _, _,_ in pred1]\n",
    "    observations_o1 = [o for _, o, _,_ in pred1]\n",
    "    true_states = [t.numpy()[:,0:1] for _, _, _,t in pred1]\n",
    "    true_states1 = [t.numpy()[:,1:2] for _, _, _,t in pred1]\n",
    "    observations_o, m1 = pad_sequences(observations_o, padding_value=-1)\n",
    "    observations_o1, m2 = pad_sequences(observations_o1, padding_value=-1)\n",
    "    observations_o=observations_o.cuda()\n",
    "    observations_o1=observations_o1.cuda()\n",
    "    m1=m1.cuda()\n",
    "    m2=m2.cuda()\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.t = 0  # Reset any time-dependent states\n",
    "\n",
    "        # Create random batch indices\n",
    "    \n",
    "\n",
    "        loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        l1,l2,_=net.training1(0, observations_o, observations_o1,m1,m2, 0.0)\n",
    "        loss -= (torch.mean(l1) + torch.mean(l2))\n",
    "\n",
    "        # Add L1 regularization\n",
    "        # l1_reg = torch.tensor(0., device=device)\n",
    "        # for param in net.parameters():\n",
    "        #     l1_reg += torch.norm(param, 1)\n",
    "\n",
    "        # # Update loss\n",
    "        # loss += 0.01 * l1_reg\n",
    "        #print(loss)\n",
    "        trial_losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Save trial results\n",
    "    print((loss.item()))\n",
    "    all_losses.append(loss.item())\n",
    "    trial_times.append(time.time() - trial_start_time)\n",
    "    final_mu_values.append(net.mu.detach().cpu().numpy())\n",
    "\n",
    "    # Save filtered states\n",
    "    net.cpu()\n",
    "    observations_o=observations_o.cpu()\n",
    "    observations_o1=observations_o1.cpu()\n",
    "    m1=m1.cpu()\n",
    "    m2=m2.cpu()\n",
    "    for i in range(0,batch_size):\n",
    "        o, o1, t, states = pred1[i]\n",
    "        o, o1 = o.to('cpu'), o1.to('cpu')\n",
    "        filtered_l1, filtered_l2 = net.state_filter(t, o, o1, 0.0)\n",
    "        trial_l1.append(torch.argmax(filtered_l1, dim=2)[0])\n",
    "        trial_l2.append(torch.argmax(filtered_l2, dim=2)[0])\n",
    "\n",
    "    all_l1.append(trial_l1)\n",
    "    all_l2.append(trial_l2)\n",
    "\n",
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)\n",
    "\n",
    "# # Plot loss curve\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for trial_losses in all_losses:\n",
    "#     plt.plot(trial_losses, alpha=0.7)\n",
    "# plt.title('Loss Curve Across Trials')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trial_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499.774658203125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(trial_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1498.321533203125,\n",
       " 1490.232666015625,\n",
       " 1489.595947265625,\n",
       " 1487.5810546875,\n",
       " 1489.57373046875,\n",
       " 1500.76025390625,\n",
       " 1497.5556640625,\n",
       " 1489.1982421875,\n",
       " 1499.416259765625,\n",
       " 1499.774658203125]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "Mean Loss (Final Epoch): -1494.2010009765625, Std Loss: 5.066932475659369\n",
      "Mean Training Time: 97.4589574098587s, Std Training Time: 27.37149124041359s\n",
      "Final mu values (across trials): [[ 0.35946414  0.01122195  0.22193769  0.6373252 ]\n",
      " [ 0.46617007  0.6663849   0.6686308   0.58256197]\n",
      " [ 0.43799865  0.68901575  0.6619625   0.3959676 ]\n",
      " [ 0.4328076   0.65964407  0.716504    0.63760626]\n",
      " [ 0.42951658  0.69157946  0.629508    0.26472297]\n",
      " [ 0.54315925  0.55577916  0.42877376  0.10294053]\n",
      " [ 0.51064533  0.5941257   0.56155974 -0.0893586 ]\n",
      " [ 0.41003922  0.70815885  0.67705554  0.69552326]\n",
      " [ 0.29917008 -0.00429746  0.24828564  0.68327296]\n",
      " [ 0.39186674  0.69835955  0.67861044  0.16396996]]\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(\"Training Results:\")\n",
    "print(f\"Mean Loss (Final Epoch): {-mean_losses}, Std Loss: {std_losses}\")\n",
    "print(f\"Mean Training Time: {mean_trial_time}s, Std Training Time: {std_trial_time}s\")\n",
    "print(f\"Final mu values (across trials): {np.array(final_mu_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Filtering MSE Results:\n",
      "Average MSE for l1: 0.8407, Std Dev: 0.2138\n",
      "Average MSE for l2: 0.9670, Std Dev: 0.0045\n",
      "Trial 1: MSE l1 = 0.4295, MSE l2 = 0.9638\n",
      "Trial 2: MSE l1 = 0.9758, MSE l2 = 0.9679\n",
      "Trial 3: MSE l1 = 0.9744, MSE l2 = 0.9678\n",
      "Trial 4: MSE l1 = 0.9728, MSE l2 = 0.9712\n",
      "Trial 5: MSE l1 = 0.9664, MSE l2 = 0.9712\n",
      "Trial 6: MSE l1 = 0.8396, MSE l2 = 0.9701\n",
      "Trial 7: MSE l1 = 0.8981, MSE l2 = 0.9649\n",
      "Trial 8: MSE l1 = 0.9755, MSE l2 = 0.9689\n",
      "Trial 9: MSE l1 = 0.4133, MSE l2 = 0.9687\n",
      "Trial 10: MSE l1 = 0.9618, MSE l2 = 0.9555\n"
     ]
    }
   ],
   "source": [
    "# State filtering MSE\n",
    "true_states = [t.numpy()[:, 0:1] for _, _, _, t in pred1]\n",
    "true_states1 = [t.numpy()[:, 1:2] for _, _, _, t in pred1]\n",
    "\n",
    "trial_mse_l1 = []\n",
    "trial_mse_l2 = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    mse_l1 = 0.0\n",
    "    mse_l2 = 0.0\n",
    "    total_states = 0\n",
    "\n",
    "    l1 = all_l1[trial]\n",
    "    l2 = all_l2[trial]\n",
    "\n",
    "    for filtered_l1, filtered_l2, ts, ts1 in zip(l1, l2, true_states, true_states1):\n",
    "        mse_l1 += (np.diag(filtered_l1.detach().numpy() == ts) ).sum()\n",
    "        # print(filtered_l1.shape)\n",
    "        # print(ts.shape)\n",
    "        mse_l2 += (np.diag(filtered_l2.detach().numpy() ==  ts1)).sum()\n",
    "        total_states += ts.shape[0]\n",
    "    # print(mse_l1)\n",
    "    # print(total_states)\n",
    "    \n",
    "\n",
    "    mse_l1 /= total_states\n",
    "    mse_l2 /= total_states\n",
    "\n",
    "    trial_mse_l1.append(mse_l1)\n",
    "    trial_mse_l2.append(mse_l2)\n",
    "\n",
    "# Calculate average error and standard deviation\n",
    "average_mse_l1 = np.mean(trial_mse_l1)\n",
    "std_mse_l1 = np.std(trial_mse_l1)\n",
    "\n",
    "average_mse_l2 = np.mean(trial_mse_l2)\n",
    "std_mse_l2 = np.std(trial_mse_l2)\n",
    "\n",
    "# Print results\n",
    "print(\"State Filtering MSE Results:\")\n",
    "print(f\"Average MSE for l1: {average_mse_l1:.4f}, Std Dev: {std_mse_l1:.4f}\")\n",
    "print(f\"Average MSE for l2: {average_mse_l2:.4f}, Std Dev: {std_mse_l2:.4f}\")\n",
    "\n",
    "# Print MSE for each trial\n",
    "for trial, (mse_l1, mse_l2) in enumerate(zip(trial_mse_l1, trial_mse_l2), 1):\n",
    "    print(f\"Trial {trial}: MSE l1 = {mse_l1:.4f}, MSE l2 = {mse_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4295409181636727,\n",
       " 0.9757884231536926,\n",
       " 0.9744111776447105,\n",
       " 0.9727744510978044,\n",
       " 0.9664271457085828,\n",
       " 0.839620758483034,\n",
       " 0.8981437125748503,\n",
       " 0.9754890219560878,\n",
       " 0.4132534930139721,\n",
       " 0.9617964071856288]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_mse_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
