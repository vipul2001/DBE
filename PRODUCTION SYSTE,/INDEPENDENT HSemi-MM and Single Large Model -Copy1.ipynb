{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)  # Set to any fixed integer\n",
    "\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)  # If using multiple GPUs\n",
    "import numpy as np\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix=torch.tensor([[0.9, 0.1, 0.0,0.0],\n",
    "        [0.00, 0.9, 0.1,0],\n",
    "        [0.0, 0.00, 0.9,.1],\n",
    "                      [0.0,0.0,0.0,1]], device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix1=torch.zeros(4,4,4)\n",
    "T_matrix1[0,:,:]=T_matrix+torch.eye(4,4)*-0.0\n",
    "T_matrix1[1,:,:]=T_matrix+torch.eye(4,4)*-0.3\n",
    "T_matrix1[2,:,:]=T_matrix+torch.eye(4,4)*-0.5\n",
    "T_matrix1[3,:,:]=T_matrix+torch.eye(4,4)*-0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix1=T_matrix1/torch.sum(T_matrix1, 2).reshape(4,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9000, 0.1000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9000, 0.1000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.8571, 0.1429, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8571, 0.1429, 0.0000],\n",
       "         [0.0000, 0.0000, 0.8571, 0.1429],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.8000, 0.2000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8000, 0.2000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.8000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.6667, 0.3333, 0.0000, 0.0000],\n",
       "         [0.0000, 0.6667, 0.3333, 0.0000],\n",
       "         [0.0000, 0.0000, 0.6667, 0.3333],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9000, 0.1000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9000, 0.1000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "\n",
    "O_matrix_mean=torch.tensor([1.5,2.5,3.5,5.5]).to(device)\n",
    "O_matrix_std=torch.tensor([1.1,1.2,1.3,1.4]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the joint state space for two units (4 states each)\n",
    "joint_states = [(i, j) for i in range(4) for j in range(4)]\n",
    "num_joint_states = len(joint_states)\n",
    "# Sort the joint states based on the sum of values in each tuple\n",
    "joint_states = sorted(joint_states, key=lambda x: sum(x))\n",
    "# Example: Define a 4x4 joint transition matrix P((s1, s2) -> (s1', s2'))\n",
    "P_joint = np.array([\n",
    "    # Each row corresponds to a joint state, each column to the next joint state\n",
    "    [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],  # (0,0) -> various states\n",
    "    [0.3, 0.3, 0.1, 0.1, 0.07, 0.05, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (0,1)\n",
    "    [0.2, 0.2, 0.3, 0.1, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,2)\n",
    "    [0.1, 0.1, 0.2, 0.4, 0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,3)\n",
    "    [0.3, 0.2, 0.1, 0.1, 0.2, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (1,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.3, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0],  # (1,1)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.4, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01, 0.0, 0.0],  # (1,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.2, 0.1, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0],  # (1,3)\n",
    "    [0.3, 0.1, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01],  # (2,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.1, 0.4, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01],  # (2,1)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.05, 0.05, 0.3, 0.05, 0.02, 0.02, 0.01, 0.01],  # (2,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.1, 0.3, 0.05, 0.05, 0.02, 0.02],  # (2,3)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.3, 0.1, 0.05, 0.05],  # (3,0)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.3, 0.05, 0.1],  # (3,1)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05, 0.1, 0.4, 0.2],  # (3,2)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # (3,3)\n",
    "])\n",
    "\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i):\n",
    "        P_joint[i, j] = 0\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i+5,16):\n",
    "        P_joint[i, j] = 0\n",
    "\n",
    "P_joint=P_joint+np.eye(16,16)*0.5\n",
    "# Normalize each row so the sum of probabilities equals 1\n",
    "P_joint = P_joint / P_joint.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Check if the rows sum to 1\n",
    "row_sums = P_joint.sum(axis=1)\n",
    "print(row_sums)  # Should all be close to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# torch.manual_seed(42)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbansal5\\AppData\\Roaming\\Python\\Python312\\site-packages\\autograd\\tracer.py:54: RuntimeWarning: divide by zero encountered in log\n",
      "  return f_raw(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04a17b1a99f4f768944be7f99fd8279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44de6489d4ce48b1a45c7727ad1c8a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4006517f38f49e98621d001c0cdd134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2792d654f2d4b1db9dcec45af098dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544c0f0bd16d4cdb86492cc4b309acf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd5a275623f453e90d1ad6f1992c39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425fa341b3e84329af013f99999c271e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9736dd4efdf14fcfa6ae3ec7d5b2a04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSMM for Machine 1: Mean Likelihood = -775.9160, Std = 174.5546, Filtration Accuracy = 0.5689\n",
      "HSMM for Machine 2: Mean Likelihood = -1230.7011, Std = 28.2838, Filtration Accuracy = 0.7763\n",
      "HSMM for Machine 3: Mean Likelihood = -672.2696, Std = 135.1598, Filtration Accuracy = 0.0472\n",
      "HSMM for Machine 4: Mean Likelihood = -697.0661, Std = 191.6754, Filtration Accuracy = 0.9343\n",
      "HSMM for Machine 5: Mean Likelihood = -652.4385, Std = 140.1201, Filtration Accuracy = 0.0017\n",
      "HSMM for Machine 6: Mean Likelihood = -1233.9329, Std = 29.0976, Filtration Accuracy = 0.0414\n",
      "HSMM for Machine 7: Mean Likelihood = -1229.0775, Std = 29.4447, Filtration Accuracy = 0.1409\n",
      "HSMM for Machine 8: Mean Likelihood = -1239.1342, Std = 22.9387, Filtration Accuracy = 0.0038\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import ssm\n",
    "\n",
    "def train_hmm_and_evaluate(observations, n_components=4, obs_type=\"gaussian\", n_iter=100):\n",
    "    \"\"\"\n",
    "    Train a Hidden Semi-Markov Model (HSMM) on the provided observations.\n",
    "\n",
    "    Parameters:\n",
    "    - observations: List of sequences of observations (each sequence should be a 2D numpy array).\n",
    "    - n_components: The number of states in the HSMM.\n",
    "    - obs_type: Type of observation model (\"gaussian\", \"bernoulli\", etc.).\n",
    "    - n_iter: Number of EM iterations for training.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained HSMM model.\n",
    "    - mean_likelihood: Mean log-likelihood of the observation sequences.\n",
    "    - std_likelihood: Standard deviation of log-likelihoods.\n",
    "    - filtered_states: List of most likely states for each observation sequence.\n",
    "    \"\"\"\n",
    "    # Flatten the data and create lengths array\n",
    "    lengths = [len(seq) for seq in observations]\n",
    "    X = np.concatenate(observations, axis=0)\n",
    "\n",
    "    # Initialize HSMM\n",
    "    hsmm = ssm.HSMM(K=n_components, D=X.shape[1], observations=obs_type,transition_kwargs={'r_min' : 1, 'r_max' : 3})\n",
    "\n",
    "    # Fit the HSMM using the EM algorithm\n",
    "    hsmm.fit(X, method=\"em\")\n",
    "\n",
    "    # Calculate log-likelihoods for each sequence\n",
    "    log_likelihoods = [hsmm.log_likelihood(seq) for seq in observations]\n",
    "    mean_likelihood = np.mean(log_likelihoods)\n",
    "    std_likelihood = np.std(log_likelihoods)\n",
    "\n",
    "    # Get filtered states for each sequence\n",
    "    filtered_states = [hsmm.most_likely_states(seq) for seq in observations]\n",
    "\n",
    "    return hsmm, mean_likelihood, std_likelihood, filtered_states\n",
    "\n",
    "\n",
    "\n",
    "# Calculate state filtration errors\n",
    "def calculate_filtration_error(filtered_states, true_states):\n",
    "    total_errors = 0\n",
    "    total_states = 0\n",
    "    for filtered, true in zip(filtered_states, true_states):\n",
    "        # print(((filtered == true)).shape)\n",
    "        total_errors +=  (np.diag(filtered == true)).sum()\n",
    "        total_states += len(true)\n",
    "        # print(total_states)\n",
    "    return total_errors / total_states\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import ssm\n",
    "\n",
    "# Load data for 8 machines\n",
    "pred1 = torch.load('DATA_NON_LINEAR_8_MACHINES.pth')\n",
    "\n",
    "# Each pred1[i] = [observations, 501, states]\n",
    "observations_all = [item[0].numpy() for item in pred1]  # shape (n_samples, 8)\n",
    "true_states_all = [item[2].numpy() for item in pred1]   # shape (n_samples, 8)\n",
    "\n",
    "n_machines = 8\n",
    "\n",
    "# Prepare data for each machine\n",
    "observations_per_machine = [\n",
    "    [obs[:, m].reshape(-1, 1) for obs in observations_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "true_states_per_machine = [\n",
    "    [states[:, m].reshape(-1, 1) for states in true_states_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "# Train and evaluate for all 8 machines\n",
    "results = []\n",
    "for m in range(n_machines):\n",
    "    model, mean_lik, std_lik, filtered_states = train_hmm_and_evaluate(observations_per_machine[m])\n",
    "    error = calculate_filtration_error(filtered_states, true_states_per_machine[m])\n",
    "    results.append((m+1, mean_lik, std_lik, error))\n",
    "\n",
    "# Print results for all machines\n",
    "for m, mean_lik, std_lik, error in results:\n",
    "    print(f\"HSMM for Machine {m}: Mean Likelihood = {mean_lik:.4f}, Std = {std_lik:.4f}, Filtration Accuracy = {error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rearrange_states(filtered_states, hmm_means):\n",
    "    \"\"\"\n",
    "    Rearranges states based on the order of HMM means.\n",
    "    \n",
    "    Args:\n",
    "        filtered_states (list of np.ndarray): List of filtered states.\n",
    "        hmm_means (np.ndarray): The means of the Gaussian HMM components.\n",
    "        \n",
    "    Returns:\n",
    "        list of np.ndarray: Rearranged filtered states.\n",
    "    \"\"\"\n",
    "    # Get the new state order by sorting the means\n",
    "    sorted_indices = np.argsort(hmm_means.flatten())\n",
    "    state_mapping = {old: new for new, old in enumerate(sorted_indices)}\n",
    "\n",
    "    # Rearrange states in the filtered results\n",
    "    rearranged_states = []\n",
    "    for states in filtered_states:\n",
    "        rearranged_states.append(np.vectorize(state_mapping.get)(states))\n",
    "    \n",
    "    return rearranged_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine 1 HMM Results:\n",
      "  Mean Likelihood: -886.4876, Std: 83.2707\n",
      "  Mean Filtration Accuracy: 0.7677, Std: 0.1910\n",
      "  Mean Computation Time: 10.5529s, Std: 11.2126s\n",
      "\n",
      "Machine 2 HMM Results:\n",
      "  Mean Likelihood: -1213.9868, Std: 20.1948\n",
      "  Mean Filtration Accuracy: 0.7006, Std: 0.3182\n",
      "  Mean Computation Time: 12.0717s, Std: 9.4830s\n",
      "\n",
      "Machine 3 HMM Results:\n",
      "  Mean Likelihood: -699.2677, Std: 26.1073\n",
      "  Mean Filtration Accuracy: 0.8182, Std: 0.1942\n",
      "  Mean Computation Time: 16.6684s, Std: 20.3578s\n",
      "\n",
      "Machine 4 HMM Results:\n",
      "  Mean Likelihood: -693.2411, Std: 27.0427\n",
      "  Mean Filtration Accuracy: 0.7350, Std: 0.2600\n",
      "  Mean Computation Time: 13.8907s, Std: 16.8824s\n",
      "\n",
      "Machine 5 HMM Results:\n",
      "  Mean Likelihood: -777.1678, Std: 103.3573\n",
      "  Mean Filtration Accuracy: 0.7602, Std: 0.1905\n",
      "  Mean Computation Time: 12.4090s, Std: 12.7839s\n",
      "\n",
      "Machine 6 HMM Results:\n",
      "  Mean Likelihood: -1217.4496, Std: 21.1520\n",
      "  Mean Filtration Accuracy: 0.6610, Std: 0.3489\n",
      "  Mean Computation Time: 17.5173s, Std: 16.2765s\n",
      "\n",
      "Machine 7 HMM Results:\n",
      "  Mean Likelihood: -1213.7465, Std: 20.8191\n",
      "  Mean Filtration Accuracy: 0.6558, Std: 0.3303\n",
      "  Mean Computation Time: 15.9341s, Std: 11.6084s\n",
      "\n",
      "Machine 8 HMM Results:\n",
      "  Mean Likelihood: -1228.9560, Std: 16.9527\n",
      "  Mean Filtration Accuracy: 0.7015, Std: 0.2827\n",
      "  Mean Computation Time: 18.2656s, Std: 20.3852s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def train_hmm_and_evaluate(observations, n_components=4, covariance_type=\"spherical\", n_iter=10000):\n",
    "    lengths = [len(seq) for seq in observations]\n",
    "    X = np.concatenate(observations)\n",
    "\n",
    "    model = hmm.GaussianHMM(n_components=n_components, covariance_type=covariance_type, n_iter=n_iter)\n",
    "    model.fit(X, lengths)\n",
    "\n",
    "    log_likelihoods = [model.score(seq) for seq in observations]\n",
    "    mean_likelihood = np.mean(log_likelihoods)\n",
    "    std_likelihood = np.std(log_likelihoods)\n",
    "\n",
    "    filtered_states = [model.predict(seq) for seq in observations]\n",
    "\n",
    "    return model, mean_likelihood, std_likelihood, filtered_states\n",
    "\n",
    "def calculate_filtration_error(filtered_states, true_states):\n",
    "    total_correct = 0\n",
    "    total_states = 0\n",
    "    for filtered, true in zip(filtered_states, true_states):\n",
    "        total_correct += (filtered.reshape(-1, 1) == true).sum()\n",
    "        total_states += len(true)\n",
    "    return total_correct / total_states\n",
    "\n",
    "# Load data\n",
    "pred1 = torch.load('DATA_NON_LINEAR_8_MACHINES.pth')\n",
    "\n",
    "# Each pred1[i] = [observations, 501, states]\n",
    "observations_all = [item[0].numpy() for item in pred1]\n",
    "true_states_all = [item[2].numpy() for item in pred1]\n",
    "\n",
    "n_machines = 8\n",
    "n_repeats = 100\n",
    "results_all = []\n",
    "time_all = []\n",
    "\n",
    "# Prepare data for each machine\n",
    "observations_per_machine = [\n",
    "    [obs[:, m].reshape(-1, 1) for obs in observations_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "true_states_per_machine = [\n",
    "    [states[:, m].reshape(-1, 1) for states in true_states_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "\n",
    "for m in range(n_machines):\n",
    "    results_m = []\n",
    "    time_m = []\n",
    "    for _ in range(n_repeats):\n",
    "        start_time = time.time()\n",
    "        model, mean_likelihood, std_likelihood, filtered_states = train_hmm_and_evaluate(observations_per_machine[m])\n",
    "        hmm_means = model.means_\n",
    "        filtered_states = rearrange_states(filtered_states, hmm_means)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        error = calculate_filtration_error(filtered_states, true_states_per_machine[m])\n",
    "        results_m.append((mean_likelihood, std_likelihood, error))\n",
    "        time_m.append(elapsed_time)\n",
    "    results_all.append(results_m)\n",
    "    time_all.append(time_m)\n",
    "\n",
    "# Calculate mean and std for metrics and time for each machine\n",
    "mean_metrics_all = [np.mean(np.array(results), axis=0) for results in results_all]\n",
    "std_metrics_all = [np.std(np.array(results), axis=0) for results in results_all]\n",
    "mean_time_all = [np.mean(times) for times in time_all]\n",
    "std_time_all = [np.std(times) for times in time_all]\n",
    "\n",
    "# Prepare output string\n",
    "output_lines = []\n",
    "for m in range(n_machines):\n",
    "    output_lines.append(f\"Machine {m+1} HMM Results:\")\n",
    "    output_lines.append(f\"  Mean Likelihood: {mean_metrics_all[m][0]:.4f}, Std: {std_metrics_all[m][0]:.4f}\")\n",
    "    output_lines.append(f\"  Mean Filtration Accuracy: {mean_metrics_all[m][2]:.4f}, Std: {std_metrics_all[m][2]:.4f}\")\n",
    "    output_lines.append(f\"  Mean Computation Time: {mean_time_all[m]:.4f}s, Std: {std_time_all[m]:.4f}s\\n\")\n",
    "\n",
    "# Save to result.txt\n",
    "with open('result_HSMM.txt', 'w') as f:\n",
    "    f.write('\\n'.join(output_lines))\n",
    "\n",
    "# Print final summary to console as well\n",
    "for line in output_lines:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
