{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)  # Set to any fixed integer\n",
    "\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)  # If using multiple GPUs\n",
    "import numpy as np\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix=torch.tensor([[0.9, 0.1, 0.0,0.0],\n",
    "        [0.00, 0.9, 0.1,0],\n",
    "        [0.0, 0.00, 0.9,.1],\n",
    "                      [0.0,0.0,0.0,1]], device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix1=torch.zeros(4,4,4)\n",
    "T_matrix1[0,:,:]=T_matrix+torch.eye(4,4)*-0.0\n",
    "T_matrix1[1,:,:]=T_matrix+torch.eye(4,4)*-0.3\n",
    "T_matrix1[2,:,:]=T_matrix+torch.eye(4,4)*-0.5\n",
    "T_matrix1[3,:,:]=T_matrix+torch.eye(4,4)*-0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix1=T_matrix1/torch.sum(T_matrix1, 2).reshape(4,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9000, 0.1000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9000, 0.1000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.8571, 0.1429, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8571, 0.1429, 0.0000],\n",
       "         [0.0000, 0.0000, 0.8571, 0.1429],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.8000, 0.2000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8000, 0.2000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.8000, 0.2000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.6667, 0.3333, 0.0000, 0.0000],\n",
       "         [0.0000, 0.6667, 0.3333, 0.0000],\n",
       "         [0.0000, 0.0000, 0.6667, 0.3333],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9000, 0.1000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9000, 0.1000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "\n",
    "O_matrix_mean=torch.tensor([1.5,2.5,3.5,5.5]).to(device)\n",
    "O_matrix_std=torch.tensor([1.1,1.2,1.3,1.4]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the joint state space for two units (4 states each)\n",
    "joint_states = [(i, j) for i in range(4) for j in range(4)]\n",
    "num_joint_states = len(joint_states)\n",
    "# Sort the joint states based on the sum of values in each tuple\n",
    "joint_states = sorted(joint_states, key=lambda x: sum(x))\n",
    "# Example: Define a 4x4 joint transition matrix P((s1, s2) -> (s1', s2'))\n",
    "P_joint = np.array([\n",
    "    # Each row corresponds to a joint state, each column to the next joint state\n",
    "    [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],  # (0,0) -> various states\n",
    "    [0.3, 0.3, 0.1, 0.1, 0.07, 0.05, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (0,1)\n",
    "    [0.2, 0.2, 0.3, 0.1, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,2)\n",
    "    [0.1, 0.1, 0.2, 0.4, 0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,3)\n",
    "    [0.3, 0.2, 0.1, 0.1, 0.2, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (1,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.3, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0],  # (1,1)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.4, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01, 0.0, 0.0],  # (1,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.2, 0.1, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0],  # (1,3)\n",
    "    [0.3, 0.1, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01],  # (2,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.1, 0.4, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01],  # (2,1)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.05, 0.05, 0.3, 0.05, 0.02, 0.02, 0.01, 0.01],  # (2,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.1, 0.3, 0.05, 0.05, 0.02, 0.02],  # (2,3)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.3, 0.1, 0.05, 0.05],  # (3,0)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.3, 0.05, 0.1],  # (3,1)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05, 0.1, 0.4, 0.2],  # (3,2)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # (3,3)\n",
    "])\n",
    "\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i):\n",
    "        P_joint[i, j] = 0\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i+5,16):\n",
    "        P_joint[i, j] = 0\n",
    "\n",
    "P_joint=P_joint+np.eye(16,16)*0.5\n",
    "# Normalize each row so the sum of probabilities equals 1\n",
    "P_joint = P_joint / P_joint.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Check if the rows sum to 1\n",
    "row_sums = P_joint.sum(axis=1)\n",
    "print(row_sums)  # Should all be close to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# torch.manual_seed(42)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed(42)\n",
    "#     torch.cuda.manual_seed_all(42)  # For multi-GPU environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine 1: Mean Likelihood = -869.3511, Std = 227.6844, Filtration Accuracy = 0.4309\n",
      "Machine 2: Mean Likelihood = -1230.4739, Std = 28.4815, Filtration Accuracy = 0.4231\n",
      "Machine 3: Mean Likelihood = -709.2651, Std = 165.3523, Filtration Accuracy = 0.3619\n",
      "Machine 4: Mean Likelihood = -666.6343, Std = 143.4310, Filtration Accuracy = 0.3920\n",
      "Machine 5: Mean Likelihood = -652.7685, Std = 140.2242, Filtration Accuracy = 0.3952\n",
      "Machine 6: Mean Likelihood = -1234.9161, Std = 29.0855, Filtration Accuracy = 0.7911\n",
      "Machine 7: Mean Likelihood = -1230.3494, Std = 29.3901, Filtration Accuracy = 0.0031\n",
      "Machine 8: Mean Likelihood = -1240.3780, Std = 23.0598, Filtration Accuracy = 0.0007\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Load data\n",
    "pred1 = torch.load('DATA_NON_LINEAR_8_MACHINES.pth')\n",
    "\n",
    "# Extract observations and underlying states for 8 machines\n",
    "# Each pred1[i] = [observations, 501, states]\n",
    "observations_all = [item[0].numpy() for item in pred1]  # shape (n_samples, 8)\n",
    "true_states_all = [item[2].numpy() for item in pred1]   # shape (n_samples, 8)\n",
    "\n",
    "n_machines = 8\n",
    "\n",
    "# Prepare data for each machine\n",
    "observations_per_machine = [\n",
    "    [obs[:, m].reshape(-1, 1) for obs in observations_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "true_states_per_machine = [\n",
    "    [states[:, m].reshape(-1, 1) for states in true_states_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "\n",
    "def train_hmm_and_evaluate(observations, n_components=4, covariance_type=\"spherical\", n_iter=10000):\n",
    "    lengths = [len(seq) for seq in observations]\n",
    "    X = np.concatenate(observations)\n",
    "\n",
    "    model = hmm.GaussianHMM(n_components=n_components, covariance_type=covariance_type, n_iter=n_iter)\n",
    "    model.fit(X, lengths)\n",
    "\n",
    "    log_likelihoods = [model.score(seq) for seq in observations]\n",
    "    mean_likelihood = np.mean(log_likelihoods)\n",
    "    std_likelihood = np.std(log_likelihoods)\n",
    "\n",
    "    filtered_states = [model.predict(seq) for seq in observations]\n",
    "\n",
    "    return model, mean_likelihood, std_likelihood, filtered_states\n",
    "\n",
    "def calculate_filtration_error(filtered_states, true_states):\n",
    "    total_correct = 0\n",
    "    total_states = 0\n",
    "    for filtered, true in zip(filtered_states, true_states):\n",
    "        total_correct += (filtered.reshape(-1, 1) == true).sum()\n",
    "        total_states += len(true)\n",
    "    return total_correct / total_states\n",
    "\n",
    "# Train HMMs for all 8 machines and collect results\n",
    "results = []\n",
    "for m in range(n_machines):\n",
    "    model, mean_lik, std_lik, filtered_states = train_hmm_and_evaluate(observations_per_machine[m])\n",
    "    error = calculate_filtration_error(filtered_states, true_states_per_machine[m])\n",
    "    results.append((m+1, mean_lik, std_lik, error))\n",
    "\n",
    "# Print results\n",
    "for m, mean_lik, std_lik, error in results:\n",
    "    print(f\"Machine {m}: Mean Likelihood = {mean_lik:.4f}, Std = {std_lik:.4f}, Filtration Accuracy = {error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rearrange_states(filtered_states, hmm_means):\n",
    "    \"\"\"\n",
    "    Rearranges states based on the order of HMM means.\n",
    "    \n",
    "    Args:\n",
    "        filtered_states (list of np.ndarray): List of filtered states.\n",
    "        hmm_means (np.ndarray): The means of the Gaussian HMM components.\n",
    "        \n",
    "    Returns:\n",
    "        list of np.ndarray: Rearranged filtered states.\n",
    "    \"\"\"\n",
    "    # Get the new state order by sorting the means\n",
    "    sorted_indices = np.argsort(hmm_means.flatten())\n",
    "    state_mapping = {old: new for new, old in enumerate(sorted_indices)}\n",
    "\n",
    "    # Rearrange states in the filtered results\n",
    "    rearranged_states = []\n",
    "    for states in filtered_states:\n",
    "        rearranged_states.append(np.vectorize(state_mapping.get)(states))\n",
    "    \n",
    "    return rearranged_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine 1 HMM Results:\n",
      "  Mean Likelihood: -870.1806, Std: 76.1045\n",
      "  Mean Filtration Accuracy: 0.7350, Std: 0.2395\n",
      "  Mean Computation Time: 10.7883s, Std: 10.8219s\n",
      "\n",
      "Machine 2 HMM Results:\n",
      "  Mean Likelihood: -1215.2039, Std: 20.3009\n",
      "  Mean Filtration Accuracy: 0.7223, Std: 0.3504\n",
      "  Mean Computation Time: 15.7606s, Std: 11.8490s\n",
      "\n",
      "Machine 3 HMM Results:\n",
      "  Mean Likelihood: -704.1236, Std: 10.6698\n",
      "  Mean Filtration Accuracy: 0.7672, Std: 0.1828\n",
      "  Mean Computation Time: 10.9705s, Std: 8.3075s\n",
      "\n",
      "Machine 4 HMM Results:\n",
      "  Mean Likelihood: -692.9789, Std: 13.3897\n",
      "  Mean Filtration Accuracy: 0.7058, Std: 0.2390\n",
      "  Mean Computation Time: 7.2397s, Std: 5.5580s\n",
      "\n",
      "Machine 5 HMM Results:\n",
      "  Mean Likelihood: -734.8101, Std: 113.7737\n",
      "  Mean Filtration Accuracy: 0.8613, Std: 0.1809\n",
      "  Mean Computation Time: 8.7942s, Std: 9.6360s\n",
      "\n",
      "Machine 6 HMM Results:\n",
      "  Mean Likelihood: -1214.0866, Std: 19.9149\n",
      "  Mean Filtration Accuracy: 0.6509, Std: 0.3467\n",
      "  Mean Computation Time: 12.8189s, Std: 11.7075s\n",
      "\n",
      "Machine 7 HMM Results:\n",
      "  Mean Likelihood: -1207.7326, Std: 22.3398\n",
      "  Mean Filtration Accuracy: 0.7219, Std: 0.3031\n",
      "  Mean Computation Time: 14.3337s, Std: 7.2145s\n",
      "\n",
      "Machine 8 HMM Results:\n",
      "  Mean Likelihood: -1228.1048, Std: 16.9754\n",
      "  Mean Filtration Accuracy: 0.7356, Std: 0.2502\n",
      "  Mean Computation Time: 9.6924s, Std: 6.3290s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def train_hmm_and_evaluate(observations, n_components=4, covariance_type=\"spherical\", n_iter=10000):\n",
    "    lengths = [len(seq) for seq in observations]\n",
    "    X = np.concatenate(observations)\n",
    "\n",
    "    model = hmm.GaussianHMM(n_components=n_components, covariance_type=covariance_type, n_iter=n_iter)\n",
    "    model.fit(X, lengths)\n",
    "\n",
    "    log_likelihoods = [model.score(seq) for seq in observations]\n",
    "    mean_likelihood = np.mean(log_likelihoods)\n",
    "    std_likelihood = np.std(log_likelihoods)\n",
    "\n",
    "    filtered_states = [model.predict(seq) for seq in observations]\n",
    "\n",
    "    return model, mean_likelihood, std_likelihood, filtered_states\n",
    "\n",
    "def calculate_filtration_error(filtered_states, true_states):\n",
    "    total_correct = 0\n",
    "    total_states = 0\n",
    "    for filtered, true in zip(filtered_states, true_states):\n",
    "        total_correct += (filtered.reshape(-1, 1) == true).sum()\n",
    "        total_states += len(true)\n",
    "    return total_correct / total_states\n",
    "\n",
    "# Load data\n",
    "pred1 = torch.load('DATA_NON_LINEAR_8_MACHINES.pth')\n",
    "\n",
    "# Each pred1[i] = [observations, 501, states]\n",
    "observations_all = [item[0].numpy() for item in pred1]\n",
    "true_states_all = [item[2].numpy() for item in pred1]\n",
    "\n",
    "n_machines = 8\n",
    "n_repeats = 10\n",
    "results_all = []\n",
    "time_all = []\n",
    "\n",
    "# Prepare data for each machine\n",
    "observations_per_machine = [\n",
    "    [obs[:, m].reshape(-1, 1) for obs in observations_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "true_states_per_machine = [\n",
    "    [states[:, m].reshape(-1, 1) for states in true_states_all]\n",
    "    for m in range(n_machines)\n",
    "]\n",
    "\n",
    "for m in range(n_machines):\n",
    "    results_m = []\n",
    "    time_m = []\n",
    "    for _ in range(n_repeats):\n",
    "        start_time = time.time()\n",
    "        model, mean_likelihood, std_likelihood, filtered_states = train_hmm_and_evaluate(observations_per_machine[m])\n",
    "        hmm_means = model.means_\n",
    "        filtered_states = rearrange_states(filtered_states, hmm_means)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        error = calculate_filtration_error(filtered_states, true_states_per_machine[m])\n",
    "        results_m.append((mean_likelihood, std_likelihood, error))\n",
    "        time_m.append(elapsed_time)\n",
    "    results_all.append(results_m)\n",
    "    time_all.append(time_m)\n",
    "\n",
    "# Calculate mean and std for metrics and time for each machine\n",
    "mean_metrics_all = [np.mean(np.array(results), axis=0) for results in results_all]\n",
    "std_metrics_all = [np.std(np.array(results), axis=0) for results in results_all]\n",
    "mean_time_all = [np.mean(times) for times in time_all]\n",
    "std_time_all = [np.std(times) for times in time_all]\n",
    "\n",
    "# Prepare output string\n",
    "output_lines = []\n",
    "for m in range(n_machines):\n",
    "    output_lines.append(f\"Machine {m+1} HMM Results:\")\n",
    "    output_lines.append(f\"  Mean Likelihood: {mean_metrics_all[m][0]:.4f}, Std: {std_metrics_all[m][0]:.4f}\")\n",
    "    output_lines.append(f\"  Mean Filtration Accuracy: {mean_metrics_all[m][2]:.4f}, Std: {std_metrics_all[m][2]:.4f}\")\n",
    "    output_lines.append(f\"  Mean Computation Time: {mean_time_all[m]:.4f}s, Std: {std_time_all[m]:.4f}s\\n\")\n",
    "\n",
    "# Save to result.txt\n",
    "with open('result_HMM.txt', 'w') as f:\n",
    "    f.write('\\n'.join(output_lines))\n",
    "\n",
    "# Print final summary to console as well\n",
    "for line in output_lines:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
