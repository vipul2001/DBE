{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([[0.9900, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9900, 0.0100, 0.0000],\n",
      "        [0.0000, 0.0000, 0.9900, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([2.3148e+00, 1.0345e+00, 1.0470e+00, 1.8620e+00, 4.0963e+00, 3.7730e+00,\n",
       "         4.5321e+00, 3.6579e+00, 3.6860e+00, 4.5186e+00, 3.5768e+00, 4.0724e+00,\n",
       "         3.1426e+00, 2.5037e+00, 4.6623e+00, 5.2655e+00, 3.6389e+00, 5.8840e+00,\n",
       "         4.9848e+00, 5.0852e-03, 1.3401e+00, 3.5348e-01, 4.8645e+00, 6.7490e+00,\n",
       "         9.1603e+00, 6.3374e+00, 6.6782e+00, 7.3330e+00, 9.7910e+00, 7.8818e+00,\n",
       "         5.8772e+00, 6.4257e+00, 6.9573e+00, 6.9095e+00, 7.9328e+00, 8.0384e+00,\n",
       "         1.0405e+01, 7.9659e+00, 6.7142e+00, 9.3992e+00, 5.1370e+00, 4.4489e+00,\n",
       "         4.5183e+00, 2.6625e+00, 3.5785e+00, 3.9485e+00, 3.6593e+00, 4.1831e+00,\n",
       "         5.7480e+00, 6.2104e+00, 8.6152e+00, 6.3951e+00, 7.4392e+00, 8.4790e+00,\n",
       "         9.0342e+00, 7.3216e+00, 9.1233e+00, 8.8293e+00, 8.8527e+00, 7.5644e+00,\n",
       "         5.9045e+00]),\n",
       " tensor([ 1.3930,  2.3273,  0.5418,  3.1852, -1.3154,  2.8284,  3.0892,  2.3866,\n",
       "          4.1579,  2.6135,  2.5753,  2.5582,  2.0435,  3.9988,  0.3993, -0.7201,\n",
       "          1.4340,  0.8647,  0.7506,  7.0384,  7.9774,  8.1437,  2.1831,  0.8691,\n",
       "          2.1222,  2.9381,  3.0736,  0.6914,  2.9668,  1.2162,  0.4074, -0.0270,\n",
       "          1.8393,  1.4822,  1.1889,  0.7529,  1.7485,  2.3658,  1.1954,  2.3233,\n",
       "          5.0021,  7.9670,  7.5936,  7.4741,  6.0435,  8.3420,  7.3368,  5.7177,\n",
       "          6.3715,  4.5568,  6.3506,  7.0615,  5.8131,  5.3121,  6.7574,  6.4466,\n",
       "          6.6562,  7.4192,  5.5825,  4.4662,  7.9025]),\n",
       " 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the joint state space for two units (4 states each)\n",
    "joint_states = [(i, j) for i in range(4) for j in range(4)]\n",
    "num_joint_states = len(joint_states)\n",
    "# Sort the joint states based on the sum of values in each tuple\n",
    "joint_states = sorted(joint_states, key=lambda x: sum(x))\n",
    "# Example: Define a 4x4 joint transition matrix P((s1, s2) -> (s1', s2'))\n",
    "P_joint = np.array([\n",
    "    # Each row corresponds to a joint state, each column to the next joint state\n",
    "    [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0],  # (0,0) -> various states\n",
    "    [0.3, 0.3, 0.1, 0.1, 0.07, 0.05, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (0,1)\n",
    "    [0.2, 0.2, 0.3, 0.1, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,2)\n",
    "    [0.1, 0.1, 0.2, 0.4, 0.05, 0.05, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0],  # (0,3)\n",
    "    [0.3, 0.2, 0.1, 0.1, 0.2, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0],  # (1,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.3, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0],  # (1,1)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.4, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.01, 0.0, 0.0],  # (1,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.2, 0.1, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0],  # (1,3)\n",
    "    [0.3, 0.1, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01],  # (2,0)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.1, 0.4, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01],  # (2,1)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.05, 0.05, 0.3, 0.05, 0.02, 0.02, 0.01, 0.01],  # (2,2)\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.1, 0.3, 0.05, 0.05, 0.02, 0.02],  # (2,3)\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.3, 0.1, 0.05, 0.05],  # (3,0)\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.05, 0.1, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.3, 0.05, 0.1],  # (3,1)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05, 0.1, 0.4, 0.2],  # (3,2)\n",
    "    [0.05, 0.05, 0.1, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # (3,3)\n",
    "])\n",
    "\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i):\n",
    "        P_joint[i, j] = 0\n",
    "# Set lower triangular elements to 0\n",
    "for i in range(16):\n",
    "    for j in range(i+5,16):\n",
    "        P_joint[i, j] = 0\n",
    "\n",
    "P_joint=P_joint+np.eye(16,16)*0.8\n",
    "# Normalize each row so the sum of probabilities equals 1\n",
    "P_joint = P_joint / P_joint.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Check if the rows sum to 1\n",
    "row_sums = P_joint.sum(axis=1)\n",
    "print(row_sums)  # Should all be close to 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P_joint\n",
    "\n",
    "\n",
    "\n",
    "T_matrix=torch.tensor([[0.99, 0.01, 0.0,0.0],\n",
    "        [0.00, 0.99, 0.01,0],\n",
    "        [0.0, 0.00, 0.99,.01],\n",
    "                      [0.0,0.0,0.0,1]], device=device) \n",
    "\n",
    "T_matrix1=torch.zeros(4,4,4)\n",
    "T_matrix1[0,:,:]=T_matrix+torch.eye(4,4)*-0.0\n",
    "T_matrix1[1,:,:]=T_matrix+torch.eye(4,4)*-0.3\n",
    "T_matrix1[2,:,:]=T_matrix+torch.eye(4,4)*-0.5\n",
    "T_matrix1[3,:,:]=T_matrix+torch.eye(4,4)*-0.7\n",
    "\n",
    "T_matrix1=T_matrix1/torch.sum(T_matrix1, 2).reshape(4,4,1)\n",
    "\n",
    "T_matrix1\n",
    "\n",
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "\n",
    "O_matrix_mean=torch.tensor([1.5,3.5,5.5,7.5]).to(device)\n",
    "O_matrix_std=torch.tensor([1.0,1.0,1.0,1.0]).to(device)\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)\n",
    "\n",
    "\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "def simulate_HMM(T_matrix_1,O_matrix,x,t):\n",
    "    x=(0,0)\n",
    "    current_state_idx = joint_states.index(x)\n",
    "    states=[]\n",
    "    t=0\n",
    "    o=[]\n",
    "    o1=[]\n",
    "#     o_1=torch.matmul(x.to(device),O_matrix.to(device))\n",
    "# #         print(o_1)\n",
    "    o.append(Normal(O_matrix_mean[x[0]],1).sample().to(device))\n",
    "    o1.append(Normal(O_matrix_mean[x[1]],1).sample().to(device))\n",
    "    t=1\n",
    "    h=torch.tensor([1,0,0,0.0])\n",
    "    states.append(x)\n",
    "    for i in range(1,5000):\n",
    "#         print(i)\n",
    "        # print(states)\n",
    "        t+=1\n",
    "        p = P_joint[current_state_idx]\n",
    "        # print(current_state_idx)\n",
    "        # Choose the next joint state based on the current transition probabilities\n",
    "        next_state_idx = np.random.choice(range(num_joint_states), p=p)\n",
    "        next_state = joint_states[next_state_idx]\n",
    "        x=next_state\n",
    "        # x[0]=x1.item()\n",
    "        # x[1]=x2.item()\n",
    "        states.append(x)\n",
    "        # print(x[0])\n",
    "        # print(alpha)\n",
    "        o_1,o_2 = MultivariateNormal(torch.stack([O_matrix_mean[x[0]], O_matrix_mean[x[1]]]), \n",
    "                                     torch.tensor([[1, 0.0],\n",
    "                              [0.0, 1]])).sample().t().to(device)\n",
    "        o.append(o_1)\n",
    "        o1.append(o_2)\n",
    "        current_state_idx=next_state_idx\n",
    "\n",
    "        \n",
    "        t1=t\n",
    "        \n",
    "        if x[0]==3 and x[1]==3:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    o=torch.tensor(o).to(device)\n",
    "    o1=torch.tensor(o1).to(device)\n",
    "    return o,o1,t\n",
    "\n",
    "o=simulate_HMM(T_matrix,O_matrix_mean,torch.tensor([1.0,0,0.0]),1000)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c9b7c133b0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "# plt.plot(o[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c9b7cd81d0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(o[0].cpu())\n",
    "plt.plot(o[1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred1=[]\n",
    "# for i in range(0, 100):\n",
    "#             pred1.append(simulate_HMM(T_matrix, O_matrix_mean, s_0, 1))\n",
    "\n",
    "# torch.save(pred1, 'DATA_NON_LINEAR.pth')\n",
    "\n",
    "# print(\"pred1 list saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MAIN MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ATTENTION(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=num_states\n",
    "        self.num_states=num_states\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K, V, t1):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.tanh(self.fc_1(attn_output))+(t1))   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=300):\n",
    "        super().__init__()\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "        \n",
    "        # self.P[:, :, 0::2] = torch.cos(X)\n",
    "        # self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "\n",
    "\n",
    "class ATTENTION1(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(ATTENTION1, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=num_states\n",
    "        self.num_states=num_states\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "\n",
    "        self.input_projection_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection1_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.input_projection2_1 = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,  Q, K,V):\n",
    "\n",
    "        seq_len = Q.size(1)\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1)\n",
    "        # print(attn_mask)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask == 1, float('-inf')).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "        \n",
    "        projected_inputs = self.input_projection_1(Q)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs1 = self.input_projection1_1(K)  # [batch, seq_len, hidden_dim]\n",
    "        projected_inputs2 = self.input_projection2_1(V)  # [batch, seq_len, hidden_dim]\n",
    "        attn_output, _ = self.attention_1(projected_inputs, projected_inputs1, projected_inputs2, attn_mask=attn_mask)  # [batch, seq_len, hidden_dim]\n",
    "        pred = (F.leaky_relu(self.fc_1(attn_output))+ V )   # [batch, seq_len, output_dim]\n",
    "\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_states=4):\n",
    "        super(Net, self).__init__()\n",
    "        num_heads=1\n",
    "        hidden_dim=4\n",
    "        num_hiddens=4\n",
    "        self.num_states=4\n",
    "        self.s_0 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.s_01 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.mu1 = nn.Parameter(torch.rand(num_states), requires_grad=True)\n",
    "        self.sigma =nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "        self.sigma1 = nn.Parameter(torch.zeros(num_states), requires_grad=True)\n",
    "\n",
    "        self.base =3*(torch.tensor([0.0,0.25,0.5,1]))\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        max_len=300\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = 3*torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1)/max_len #/ torch.pow(10000, torch.arange(\n",
    "            #0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        for i in range(4):\n",
    "            self.P[:, :, i:i+1] = torch.cos(self.base[i]-X)\n",
    "\n",
    "        \n",
    "        self.input_dim = num_states\n",
    "        input_dim=num_states\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc1 = nn.Linear(input_dim+1 ,hidden_dim,bias=False)\n",
    "        self.fc2 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc3 = nn.Linear(1 ,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        \n",
    "        self.A1=ATTENTION()\n",
    "        self.A2=ATTENTION()\n",
    "        self.A3=ATTENTION()\n",
    "        self.A4=ATTENTION()\n",
    "        self.A5=ATTENTION()\n",
    "        self.A6=ATTENTION()\n",
    "        self.A7=ATTENTION()\n",
    "        self.A8=ATTENTION()\n",
    "        self.A9=ATTENTION()\n",
    "        self.A10=ATTENTION()\n",
    "\n",
    "        # LSTM Encoder\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm3 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.lstm4 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        \n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(hidden_dim, 0)\n",
    "    def forward(self,  t, pred,pred1, prob=0.3):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def training1(self,  t, pred,pred1,m1,m2, prob=0.0):\n",
    "\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        #pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        #pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            #print(o_1.shape)\n",
    "            #print(new_pred[:,:,i].shape)\n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone().unsqueeze(2).repeat(1,1,4).clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states)).cuda()\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states)).cuda()\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(pred.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "    \n",
    "        KL=torch.sum(F.softmax(pred_1, dim=2)*torch.log(pred[0,:-1]/F.softmax(pred_1, dim=2)))\n",
    "        KL+=torch.sum(F.softmax(pred1_1, dim=2)*torch.log(pred1[0,:-1]/F.softmax(pred1_1, dim=2)))\n",
    "        \n",
    "        pred_1=torch.sum(pred_1, dim=2)\n",
    "        pred_1=torch.log(pred_1)\n",
    "        pred_1=torch.sum(pred_1*m1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.sum(pred1_1, dim=2)\n",
    "        pred1_1=torch.log(pred1_1)\n",
    "        pred1_1=torch.sum(pred1_1*m2, dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return pred_1, pred1_1,KL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def state_filter(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "       \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "            pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred_1, pred1_1\n",
    "        \n",
    "    def state_filter1(self,  t, pred,pred1, prob=0.0):\n",
    "        s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "        s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(4,1,1)\n",
    "\n",
    "        # print(s_0.shape)\n",
    "        exp_mu = torch.exp(self.mu)           # Step 1: Take exponential\n",
    "        cumsum_mu = torch.cumsum(exp_mu, dim=0)\n",
    "\n",
    "\n",
    "        exp_mu1 = torch.exp(self.mu1)           # Step 1: Take exponential\n",
    "        cumsum_mu1 = torch.cumsum(exp_mu1, dim=0)\n",
    "\n",
    "        \n",
    "        pred_base=pred.clone()\n",
    "        pred1_base=pred1.clone()\n",
    "\n",
    "        pred=pred.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "        pred1=pred1.unsqueeze(0).repeat(1,1).unsqueeze(2).repeat(4,1,4).clone()\n",
    "\n",
    "        new_pred = pred.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "            \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred=new_pred.clone()\n",
    "        \n",
    "        new_pred = pred1.clone()\n",
    "        for i in range(self.num_states):\n",
    "            dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "            o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "            new_pred[:,:,i] = o_1#*1/self.num_states\n",
    "        pred1=new_pred.clone()\n",
    "\n",
    "        # Generate a binary mask to decide which timestamps to replace\n",
    "        mask = (torch.rand(4, pred.shape[1], 1, device=pred.device) < prob).float()\n",
    "        replacement = torch.full_like(pred, -1.0)\n",
    "        pred = pred * (1 - mask) + replacement * mask\n",
    "        pred1 = pred1 * (1 - mask) + replacement * mask\n",
    "        \n",
    "        # print(pred.shape)\n",
    "        pred=pred/torch.sum(pred,dim=2, keepdim=True)\n",
    "        pred1=pred1/torch.sum(pred1,dim=2, keepdim=True)\n",
    "        # print(pred[0,0])\n",
    "\n",
    "        position = torch.arange(0, t, device=device).unsqueeze(0).repeat(4,1).unsqueeze(2).float()\n",
    "        # print(position.shape)\n",
    "        t1=F.tanh(self.fc2(position)).float()\n",
    "        t2=F.tanh(self.fc3(position)).float()\n",
    "        # t2=self.fc3(position).float()\n",
    "        # pred=torch.concat([pred, position], dim=2)\n",
    "        # pred1=torch.concat([pred1, position], dim=2)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # pred = F.leaky_relu(self.fc(pred))\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1))\n",
    "        pred_base1=pred.clone()\n",
    "        pred1_base1=pred1.clone()\n",
    "\n",
    "        pred_1, _ = self.lstm1(pred)\n",
    "        pred1_1, _ = self.lstm2(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "        \n",
    "        # pred = F.leaky_relu(self.fc(pred)) + P\n",
    "        # pred1 = F.leaky_relu(self.fc1(pred1)) + P\n",
    "        # pred = pred + t1\n",
    "        # pred1 = pred1 + t1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        pred=self.A1(pred,pred,pred,pred_base1)\n",
    "        # pred=self.A2(pred,pred,pred,t1)\n",
    "        # pred=self.A3(pred,pred,pred,t1)\n",
    "\n",
    "        \n",
    "        pred1=self.A4(pred1,pred1,pred1,pred1_base1)\n",
    "        # pred1=self.A5(pred1,pred1,pred1,t1)\n",
    "        # pred1=self.A6(pred1,pred1,pred1,t1)\n",
    "\n",
    "        pred_1, _ = self.lstm3(pred)\n",
    "        pred1_1, _ = self.lstm4(pred1)\n",
    "        pred=F.tanh(pred)+pred_1\n",
    "        pred1=F.tanh(pred1)+pred1_1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        pred_1=self.A7(pred,pred1,pred,pred)\n",
    "        # pred_1=self.A8(pred_1,pred1,pred_1)\n",
    "\n",
    "        \n",
    "        pred1_1=self.A9(pred1,pred ,pred1,pred1)\n",
    "        # pred1_1=self.A10(pred1_1,pred ,pred1_1)\n",
    "\n",
    "        pred=pred_1.clone()\n",
    "        pred1=pred1_1.clone()\n",
    "\n",
    "\n",
    "        pred = F.softmax(self.fc4(pred)+pred, dim=2)\n",
    "        pred1 = F.softmax(self.fc5(pred1)+pred1, dim=2)\n",
    "\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        pred_1=torch.zeros((pred.shape[0], pred.shape[1],self.num_states))\n",
    "        pred1_1=torch.zeros((pred1.shape[0], pred1.shape[1],self.num_states))\n",
    "        pred=torch.concat([s_0,pred], dim=1)\n",
    "        pred1=torch.concat([s_01,pred1], dim=1)\n",
    "        # print(pred.shape)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu[i], torch.exp(self.sigma[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred_base))\n",
    "             \n",
    "        #     pred_1[:,:,i] = o_1*pred[:,:-1,i] \n",
    "\n",
    "\n",
    "        # for i in range(self.num_states):\n",
    "        #     dist = Normal(cumsum_mu1[i], torch.exp(self.sigma1[i]))\n",
    "        #     o_1 = torch.exp(dist.log_prob(pred1_base))\n",
    "             \n",
    "        #     pred1_1[:,:,i] = o_1*pred1[:,:-1,i] \n",
    "\n",
    "\n",
    "        # pred_1=torch.softmax(pred_1, dim=2)\n",
    "        # pred_1=torch.log(pred_1)\n",
    "        # pred_1=torch.sum(pred_1, dim=1)\n",
    "\n",
    "\n",
    "        # pred1_1=torch.softmax(pred1_1, dim=2)\n",
    "        # pred1_1=torch.log(pred1_1)\n",
    "        # pred1_1=torch.sum(pred1_1, dim=1)\n",
    "\n",
    "\n",
    "        return pred, pred1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with a padding value.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = torch.full((len(sequences), max_length), padding_value, dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "    \n",
    "    return padded_sequences, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with the last value of each sequence.\n",
    "    Returns the padded sequences and a mask indicating the original positions.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = torch.zeros((len(sequences), max_length), dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "        \n",
    "        # Fill the remaining positions with the last value of the sequence\n",
    "        if length > 0:  # Check to ensure sequence is not empty\n",
    "            padded_sequences[i, length:] = seq[-1]\n",
    "    \n",
    "    return padded_sequences, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of variable-length sequences with the last value of each sequence.\n",
    "    Returns the padded sequences and a mask indicating the original positions.\n",
    "    \"\"\"\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    print(max_length)\n",
    "    padded_sequences = torch.zeros((len(sequences), max_length), dtype=torch.float32)\n",
    "    mask = torch.zeros((len(sequences), max_length), dtype=torch.bool)\n",
    "    # Collect the last values from all sequences\n",
    "    last_values = [seq[-1] for seq in sequences if len(seq) > 0]\n",
    "    last_values_tensor = torch.tensor(last_values, dtype=torch.float32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
    "        mask[i, :length] = True\n",
    "        \n",
    "        if length > 0:  # Ensure the sequence is not empty\n",
    "            random_indices = torch.randint(0, len(last_values_tensor), (max_length - length,))\n",
    "            random_values = last_values_tensor[random_indices]\n",
    "            padded_sequences[i, length:] = random_values\n",
    "    \n",
    "    return padded_sequences, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "def var_diff(o_1):\n",
    "    return torch.sum(o_1[1])\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n",
    "\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=(e2-e1)**2\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4288\\3374062728.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pred1 = torch.load('TRAIN_DATA_NON_LINEAR.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4288\\502618589.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_sequences[i, :length] = torch.tensor(seq, dtype=torch.float32)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4288\\4031529318.py:222: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_0=F.softmax(self.s_0).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4288\\4031529318.py:223: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_01=F.softmax(self.s_01).unsqueeze(0).repeat(1,1).unsqueeze(1).repeat(100,1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-428.811279296875\n",
      "tensor([-8.3838, -1.8342,  5.0869, -0.1643], device='cuda:0')\n",
      "tensor([1.5054, 2.3617, 3.5449, 6.6999], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 2/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.1467590332031\n",
      "tensor([-17.3346,  -5.4423,  -2.0754,  -0.3948], device='cuda:0')\n",
      "tensor([1.5041, 2.3615, 3.5405, 6.6914], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 3/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.8321533203125\n",
      "tensor([-2.0250,  0.3265,  1.2705,  0.8174], device='cuda:0')\n",
      "tensor([1.5033, 2.3601, 3.5487, 6.7035], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 4/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-429.6386413574219\n",
      "tensor([-1.1204e+01, -9.6756e+00,  1.7418e+00,  1.1337e-03], device='cuda:0')\n",
      "tensor([1.5081, 2.3621, 3.5206, 3.5213], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 5/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-429.80950927734375\n",
      "tensor([-2.9287e-02, -3.1759e-03,  2.1424e-03,  8.0874e-05], device='cuda:0')\n",
      "tensor([1.5001, 2.3594, 3.5406, 6.7044], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 6/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-431.882080078125\n",
      "tensor([13.0761,  5.9501,  2.0142,  0.1353], device='cuda:0')\n",
      "tensor([1.5142, 2.3673, 3.5405, 6.6935], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 7/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-428.4390563964844\n",
      "tensor([8.6114, 3.5006, 0.5400, 0.0661], device='cuda:0')\n",
      "tensor([1.5066, 2.3624, 3.5343, 6.6957], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 8/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-432.53277587890625\n",
      "tensor([-55.5164, -20.5531,  -6.3530,  -0.2138], device='cuda:0')\n",
      "tensor([1.5047, 2.3631, 3.5445, 6.7035], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 9/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-430.2759704589844\n",
      "tensor([11.9908, -0.6076, -0.7664,  0.3241], device='cuda:0')\n",
      "tensor([1.5050, 2.3589, 3.5249, 6.7054], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n",
      "Trial 10/10\n",
      "362\n",
      "362\n",
      "tensor(20630, device='cuda:0')\n",
      "tensor(26657, device='cuda:0')\n",
      "-497.2584228515625\n",
      "tensor([26.3132,  9.2862, 12.0457,  1.1348], device='cuda:0')\n",
      "tensor([1.9096, 3.4174, 6.6970, 7.0146], device='cuda:0',\n",
      "       grad_fn=<CumsumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "pred1 = torch.load('TRAIN_DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Parameters for experiment\n",
    "batch_size = 100\n",
    "num_epochs = 10000\n",
    "n_trials = 10\n",
    "learning_rate = 0.01\n",
    "device='cuda'\n",
    "# Initialize result containers\n",
    "all_losses = []\n",
    "all_l1 = []\n",
    "all_l2 = []\n",
    "trial_times = []\n",
    "final_mu_values = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial {trial + 1}/{n_trials}\")\n",
    "    trial_start_time = time.time()\n",
    "\n",
    "    net = Net().to(device)  # Initialize model\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=num_epochs)\n",
    "\n",
    "    net.train()\n",
    "    trial_losses = []\n",
    "    trial_l1 = []\n",
    "    trial_l2 = []\n",
    "    # Extract observations and underlying states\n",
    "    observations_o = [o for o, _, _ in pred1]\n",
    "    observations_o1 = [o for _, o, _ in pred1]\n",
    "   \n",
    "    observations_o, m1 = pad_sequences(observations_o, padding_value=-1)\n",
    "    observations_o1, m2 = pad_sequences(observations_o1, padding_value=-1)\n",
    "    observations_o=observations_o.cuda()\n",
    "    observations_o1=observations_o1.cuda()\n",
    "    m1=m1.cuda()\n",
    "    m2=m2.cuda()\n",
    "    m_1=m1.clone()\n",
    "    m_2=m2.clone()\n",
    "    print(m1.sum())\n",
    "    m_1[:,:-100]=1\n",
    "    m_2[:,:-100]=1\n",
    "    print(m_1.sum())\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.t = 0  # Reset any time-dependent states\n",
    "\n",
    "        # Create random batch indices\n",
    "    \n",
    "\n",
    "        loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        l1,l2,_=net.training1(0, observations_o, observations_o1,m_1,m_2, 0.0)\n",
    "        loss -= (torch.mean(l1) + torch.mean(l2))\n",
    "\n",
    "        # Add L1 regularization\n",
    "        # l1_reg = torch.tensor(0., device=device)\n",
    "        # for param in net.parameters():\n",
    "        #     l1_reg += torch.norm(param, 1)\n",
    "\n",
    "        # # Update loss\n",
    "        # loss += 0.01 * l1_reg\n",
    "        #print(loss)\n",
    "        trial_losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    l1,l2,_=net.training1(0, observations_o, observations_o1,m1,m2, 0.0)\n",
    "    loss = (torch.mean(l1) + torch.mean(l2))\n",
    "    # Save trial results\n",
    "    print((loss.item()))\n",
    "    print(net.mu.grad)\n",
    "    print(torch.cumsum(torch.exp(net.mu),dim=0))\n",
    "    all_losses.append(loss.item())\n",
    "    trial_times.append(time.time() - trial_start_time)\n",
    "    final_mu_values.append(torch.cumsum(torch.exp(net.mu),dim=0).detach().cpu().numpy())\n",
    "\n",
    "    # Save filtered states\n",
    "    net.cpu()\n",
    "    observations_o=observations_o.cpu()\n",
    "    observations_o1=observations_o1.cpu()\n",
    "   \n",
    "\n",
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)\n",
    "\n",
    "# # Plot loss curve\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for trial_losses in all_losses:\n",
    "#     plt.plot(trial_losses, alpha=0.7)\n",
    "# plt.title('Loss Curve Across Trials')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.5053728, 2.3616877, 3.5448809, 6.699907 ], dtype=float32),\n",
       " array([1.5041384, 2.3614569, 3.5404842, 6.691352 ], dtype=float32),\n",
       " array([1.5033318, 2.3601394, 3.5486639, 6.7034693], dtype=float32),\n",
       " array([1.508141 , 2.3621278, 3.520622 , 3.5213478], dtype=float32),\n",
       " array([1.5000691, 2.3593743, 3.5406332, 6.704445 ], dtype=float32),\n",
       " array([1.5142398, 2.3673391, 3.5404847, 6.69354  ], dtype=float32),\n",
       " array([1.506558 , 2.36244  , 3.5342753, 6.695673 ], dtype=float32),\n",
       " array([1.504707 , 2.3630967, 3.5444999, 6.7035255], dtype=float32),\n",
       " array([1.5050359, 2.3589084, 3.5249138, 6.7053576], dtype=float32),\n",
       " array([1.9096323, 3.4173648, 6.697022 , 7.014581 ], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mu_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred1 = torch.load('DATA_NON_LINEAR.pth')\n",
    "\n",
    "# Parameters for experiment\n",
    "batch_size = 100\n",
    "num_epochs = 10000\n",
    "n_trials = 10\n",
    "learning_rate = 0.01\n",
    "device='cuda'\n",
    "# Initialize result containers\n",
    "all_losses = []\n",
    "all_l1 = []\n",
    "all_l2 = []\n",
    "trial_times = []\n",
    "final_mu_values = []\n",
    "# Parameters for early stopping\n",
    "patience = 200000  # Number of epochs to wait for improvement\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    print(f\"Trial {trial + 1}/{n_trials}\")\n",
    "    trial_start_time = time.time()\n",
    "\n",
    "    net = Net().to(device)  # Initialize model\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.0001, total_iters=num_epochs)\n",
    "\n",
    "    net.train()\n",
    "    trial_losses = []\n",
    "    trial_l1 = []\n",
    "    trial_l2 = []\n",
    "    # Extract observations and underlying states\n",
    "    observations_o = [o for o, _, _, _ in pred1]\n",
    "    observations_o1 = [o for _, o, _, _ in pred1]\n",
    "    true_states = [t.numpy()[:, 0:1] for _, _, _, t in pred1]\n",
    "    true_states1 = [t.numpy()[:, 1:2] for _, _, _, t in pred1]\n",
    "    observations_o, m1 = pad_sequences(observations_o, padding_value=-1)\n",
    "    observations_o1, m2 = pad_sequences(observations_o1, padding_value=-1)\n",
    "    observations_o = observations_o.cuda()\n",
    "    observations_o1 = observations_o1.cuda()\n",
    "    m1 = m1.cuda()\n",
    "    m2 = m2.cuda()\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        net.t = 0  # Reset any time-dependent states\n",
    "\n",
    "        # Create random batch indices\n",
    "        loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        l1, l2, _ = net.training1(0, observations_o, observations_o1, m1, m2, 0.0)\n",
    "        loss -= (torch.mean(l1) + torch.mean(l2))\n",
    "\n",
    "        trial_losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Check early stopping\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model_state = net.state_dict()  # Save the best model state\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Save trial results\n",
    "    print(f\"Final Loss for Trial {trial + 1}: {loss.item()}\")\n",
    "    all_losses.append(best_loss)\n",
    "    trial_times.append(time.time() - trial_start_time)\n",
    "    final_mu_values.append(net.mu.detach().cpu().numpy())\n",
    "\n",
    "    # Load the best model state for evaluation\n",
    "    net.load_state_dict(best_model_state)\n",
    "\n",
    "    # Save filtered states\n",
    "    net.cpu()\n",
    "    observations_o = observations_o.cpu()\n",
    "    observations_o1 = observations_o1.cpu()\n",
    "    m1 = m1.cpu()\n",
    "    m2 = m2.cpu()\n",
    "    for i in range(0, batch_size):\n",
    "        o, o1, t, states = pred1[i]\n",
    "        o, o1 = o.to('cpu'), o1.to('cpu')\n",
    "        filtered_l1, filtered_l2 = net.state_filter(t, o, o1, 0.0)\n",
    "        trial_l1.append(torch.argmax(filtered_l1, dim=2)[0])\n",
    "        trial_l2.append(torch.argmax(filtered_l2, dim=2)[0])\n",
    "\n",
    "    all_l1.append(trial_l1)\n",
    "    all_l2.append(trial_l2)\n",
    "\n",
    "# Compute statistics across trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc): Linear(in_features=5, out_features=4, bias=False)\n",
       "  (fc1): Linear(in_features=5, out_features=4, bias=False)\n",
       "  (fc2): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (fc3): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (fc4): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (fc5): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (A1): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A2): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A3): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A4): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A5): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A6): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A7): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A8): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A9): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (A10): ATTENTION(\n",
       "    (input_projection_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection1_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (input_projection2_1): Linear(in_features=4, out_features=4, bias=False)\n",
       "    (attention_1): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc_1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (lstm1): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm2): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm3): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (lstm4): LSTM(4, 4, num_layers=2, batch_first=True)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trial_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657.2269287109375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(trial_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-428.811279296875,\n",
       " -431.1467590332031,\n",
       " -431.8321533203125,\n",
       " -429.6386413574219,\n",
       " -429.80950927734375,\n",
       " -431.882080078125,\n",
       " -428.4390563964844,\n",
       " -432.53277587890625,\n",
       " -430.2759704589844,\n",
       " -497.2584228515625]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics across trials\n",
    "mean_losses = np.mean(all_losses, axis=0)\n",
    "std_losses = np.std(all_losses, axis=0)\n",
    "mean_trial_time = np.mean(trial_times)\n",
    "std_trial_time = np.std(trial_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "Mean Loss (Final Epoch): 437.16266479492185, Std Loss: 20.073314186500625\n",
      "Mean Training Time: 2534.9514289855956s, Std Training Time: 109.85633760652307s\n",
      "Final mu values (across trials): [[1.5053728 2.3616877 3.5448809 6.699907 ]\n",
      " [1.5041384 2.3614569 3.5404842 6.691352 ]\n",
      " [1.5033318 2.3601394 3.5486639 6.7034693]\n",
      " [1.508141  2.3621278 3.520622  3.5213478]\n",
      " [1.5000691 2.3593743 3.5406332 6.704445 ]\n",
      " [1.5142398 2.3673391 3.5404847 6.69354  ]\n",
      " [1.506558  2.36244   3.5342753 6.695673 ]\n",
      " [1.504707  2.3630967 3.5444999 6.7035255]\n",
      " [1.5050359 2.3589084 3.5249138 6.7053576]\n",
      " [1.9096323 3.4173648 6.697022  7.014581 ]]\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(\"Training Results:\")\n",
    "print(f\"Mean Loss (Final Epoch): {-mean_losses}, Std Loss: {std_losses}\")\n",
    "print(f\"Mean Training Time: {mean_trial_time}s, Std Training Time: {std_trial_time}s\")\n",
    "print(f\"Final mu values (across trials): {np.array(final_mu_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred1[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pred1[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State filtering MSE\n",
    "true_states = [t.numpy()[:, 0:1] for _, _, _, t in pred1]\n",
    "true_states1 = [t.numpy()[:, 1:2] for _, _, _, t in pred1]\n",
    "\n",
    "trial_mse_l1 = []\n",
    "trial_mse_l2 = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    mse_l1 = 0.0\n",
    "    mse_l2 = 0.0\n",
    "    total_states = 0\n",
    "\n",
    "    l1 = all_l1[trial]\n",
    "    l2 = all_l2[trial]\n",
    "\n",
    "    for filtered_l1, filtered_l2, ts, ts1 in zip(l1, l2, true_states, true_states1):\n",
    "        mse_l1 += (np.diag(filtered_l1.detach().numpy() == ts) ).sum()\n",
    "        # print(filtered_l1.shape)\n",
    "        # print(ts.shape)\n",
    "        mse_l2 += (np.diag(filtered_l2.detach().numpy() ==  ts1)).sum()\n",
    "        total_states += ts.shape[0]\n",
    "    # print(mse_l1)\n",
    "    # print(total_states)\n",
    "    \n",
    "\n",
    "    mse_l1 /= total_states\n",
    "    mse_l2 /= total_states\n",
    "\n",
    "    trial_mse_l1.append(mse_l1)\n",
    "    trial_mse_l2.append(mse_l2)\n",
    "\n",
    "# Calculate average error and standard deviation\n",
    "average_mse_l1 = np.mean(trial_mse_l1)\n",
    "std_mse_l1 = np.std(trial_mse_l1)\n",
    "\n",
    "average_mse_l2 = np.mean(trial_mse_l2)\n",
    "std_mse_l2 = np.std(trial_mse_l2)\n",
    "\n",
    "# Print results\n",
    "print(\"State Filtering MSE Results:\")\n",
    "print(f\"Average MSE for l1: {average_mse_l1:.4f}, Std Dev: {std_mse_l1:.4f}\")\n",
    "print(f\"Average MSE for l2: {average_mse_l2:.4f}, Std Dev: {std_mse_l2:.4f}\")\n",
    "\n",
    "# Print MSE for each trial\n",
    "for trial, (mse_l1, mse_l2) in enumerate(zip(trial_mse_l1, trial_mse_l2), 1):\n",
    "    print(f\"Trial {trial}: MSE l1 = {mse_l1:.4f}, MSE l2 = {mse_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_mse_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_mse_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of parameters\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
